{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80ffcae0-9678-412c-bd40-fdcb176286da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c699f634-ddf4-44b8-adfc-16abe94f5ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 3, 3, 1])\n"
     ]
    }
   ],
   "source": [
    "# vector\n",
    "vec = torch.tensor([1,3,3,1])\n",
    "print(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d199a53f-6b72-446f-a9c2-7f19e1d6926c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 4],\n",
      "        [2, 3, 1]])\n"
     ]
    }
   ],
   "source": [
    "# 3d tensor\n",
    "ten_2d = torch.tensor([[1,2,4],[2,3,1]])\n",
    "print(ten_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09abe2a5-309e-4eb4-91f5-55eb4d0b6559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 4, 8],\n",
       "        [4, 6, 2]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# multplication \n",
    "mult = ten_2d * 2\n",
    "mult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "068b9b8f-8db0-4fd3-90a3-2fd96605d8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = torch.rand(4,28,28)\n",
    "\n",
    "second_image = images[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3511646f-96db-4716-99b1-4a247627e323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6449, 0.4255, 0.0227, 0.8832, 0.0593, 0.8001, 0.2389, 0.8410, 0.3930,\n",
       "         0.2549, 0.9066, 0.5673, 0.2115, 0.3306, 0.3119, 0.1734, 0.8626, 0.1566,\n",
       "         0.1843, 0.4543, 0.5136, 0.6275, 0.8216, 0.9480, 0.5375, 0.9474, 0.1113,\n",
       "         0.4695],\n",
       "        [0.9901, 0.2169, 0.4241, 0.1279, 0.4998, 0.4417, 0.3024, 0.4713, 0.1065,\n",
       "         0.9810, 0.0677, 0.4860, 0.5776, 0.6768, 0.2128, 0.6662, 0.1025, 0.5922,\n",
       "         0.7230, 0.6424, 0.7280, 0.5057, 0.9729, 0.1652, 0.7894, 0.3159, 0.9671,\n",
       "         0.6054],\n",
       "        [0.5323, 0.4295, 0.0404, 0.3873, 0.8375, 0.9470, 0.6601, 0.3328, 0.6711,\n",
       "         0.4021, 0.7751, 0.9185, 0.9398, 0.5005, 0.3391, 0.8983, 0.1794, 0.3976,\n",
       "         0.9019, 0.3355, 0.6721, 0.7733, 0.1978, 0.8691, 0.9807, 0.3154, 0.3378,\n",
       "         0.8439],\n",
       "        [0.6382, 0.6425, 0.3441, 0.0386, 0.7225, 0.7083, 0.1111, 0.5841, 0.8443,\n",
       "         0.4989, 0.5580, 0.8818, 0.1139, 0.9202, 0.1164, 0.5621, 0.2712, 0.8188,\n",
       "         0.0985, 0.7538, 0.4323, 0.0798, 0.3062, 0.0168, 0.2870, 0.6261, 0.3324,\n",
       "         0.4451],\n",
       "        [0.5078, 0.0337, 0.8919, 0.7556, 0.5871, 0.3745, 0.2775, 0.6253, 0.1958,\n",
       "         0.6314, 0.8731, 0.9913, 0.4345, 0.4319, 0.6954, 0.4050, 0.8285, 0.4374,\n",
       "         0.6704, 0.7329, 0.4282, 0.9335, 0.2861, 0.2196, 0.8264, 0.5033, 0.4366,\n",
       "         0.2301],\n",
       "        [0.1747, 0.6219, 0.0993, 0.1709, 0.9822, 0.9034, 0.3110, 0.9121, 0.7650,\n",
       "         0.5883, 0.5094, 0.3965, 0.4138, 0.1859, 0.8895, 0.8319, 0.6839, 0.7295,\n",
       "         0.5232, 0.0710, 0.5706, 0.5169, 0.1255, 0.7097, 0.6739, 0.4697, 0.1124,\n",
       "         0.5181],\n",
       "        [0.2955, 0.8638, 0.4686, 0.9482, 0.3720, 0.2228, 0.8221, 0.3022, 0.1226,\n",
       "         0.3822, 0.4692, 0.3095, 0.5829, 0.3017, 0.6384, 0.4685, 0.3607, 0.5754,\n",
       "         0.8578, 0.2203, 0.1165, 0.3712, 0.7441, 0.0386, 0.7038, 0.6336, 0.4102,\n",
       "         0.9072],\n",
       "        [0.9581, 0.5110, 0.0181, 0.8074, 0.1108, 0.9892, 0.1608, 0.6162, 0.6694,\n",
       "         0.6221, 0.0469, 0.6891, 0.2914, 0.3753, 0.8915, 0.4423, 0.0774, 0.7266,\n",
       "         0.1281, 0.1666, 0.4613, 0.5278, 0.5773, 0.3477, 0.3264, 0.8199, 0.9454,\n",
       "         0.5112],\n",
       "        [0.0958, 0.9430, 0.2766, 0.9150, 0.6165, 0.4547, 0.2654, 0.6867, 0.5832,\n",
       "         0.1112, 0.0488, 0.2058, 0.4335, 0.0926, 0.9774, 0.3726, 0.2670, 0.9191,\n",
       "         0.3285, 0.4376, 0.9422, 0.7870, 0.4684, 0.0952, 0.0977, 0.2433, 0.0731,\n",
       "         0.3182],\n",
       "        [0.3357, 0.3859, 0.2371, 0.0794, 0.7073, 0.7377, 0.8499, 0.4767, 0.3802,\n",
       "         0.9394, 0.9110, 0.4853, 0.6935, 0.7330, 0.7977, 0.8228, 0.0810, 0.2245,\n",
       "         0.1622, 0.1751, 0.2415, 0.7395, 0.6672, 0.6224, 0.4585, 0.5661, 0.4294,\n",
       "         0.5430],\n",
       "        [0.4486, 0.5413, 0.2450, 0.3149, 0.9432, 0.2446, 0.6047, 0.4439, 0.3406,\n",
       "         0.9358, 0.2929, 0.4423, 0.2271, 0.9935, 0.2577, 0.4999, 0.9677, 0.6865,\n",
       "         0.1288, 0.4625, 0.3751, 0.8300, 0.4723, 0.5179, 0.4357, 0.1292, 0.7972,\n",
       "         0.4398],\n",
       "        [0.5349, 0.5304, 0.9930, 0.5422, 0.1145, 0.1182, 0.5378, 0.4253, 0.7306,\n",
       "         0.2670, 0.6257, 0.6246, 0.6281, 0.0586, 0.2338, 0.5724, 0.3503, 0.2087,\n",
       "         0.1924, 0.8982, 0.1939, 0.1209, 0.1234, 0.4778, 0.3497, 0.8489, 0.8907,\n",
       "         0.8298],\n",
       "        [0.8013, 0.1241, 0.9420, 0.2775, 0.2734, 0.2375, 0.6035, 0.4647, 0.3167,\n",
       "         0.9336, 0.2758, 0.5072, 0.4384, 0.5161, 0.8226, 0.4080, 0.1341, 0.5580,\n",
       "         0.3293, 0.0817, 0.3641, 0.4003, 0.2041, 0.0053, 0.3584, 0.1160, 0.6005,\n",
       "         0.4992],\n",
       "        [0.3709, 0.0042, 0.8078, 0.3260, 0.4827, 0.0529, 0.1508, 0.5349, 0.1476,\n",
       "         0.0072, 0.5204, 0.5818, 0.3534, 0.4057, 0.4581, 0.4976, 0.2659, 0.1666,\n",
       "         0.1512, 0.6052, 0.5188, 0.5660, 0.7006, 0.8754, 0.1975, 0.4360, 0.2542,\n",
       "         0.3883],\n",
       "        [0.6460, 0.6377, 0.8678, 0.3985, 0.4593, 0.5906, 0.0584, 0.0579, 0.5064,\n",
       "         0.3858, 0.9037, 0.2602, 0.5042, 0.2617, 0.5021, 0.0055, 0.4777, 0.8712,\n",
       "         0.0880, 0.5219, 0.0611, 0.6036, 0.0114, 0.4551, 0.4850, 0.2922, 0.8600,\n",
       "         0.0432],\n",
       "        [0.0176, 0.0362, 0.6365, 0.6629, 0.6725, 0.1555, 0.0138, 0.5047, 0.5444,\n",
       "         0.1201, 0.7730, 0.4688, 0.4214, 0.5478, 0.6149, 0.9748, 0.6882, 0.5684,\n",
       "         0.1215, 0.6993, 0.9363, 0.4562, 0.2267, 0.7182, 0.1728, 0.9441, 0.8953,\n",
       "         0.2781],\n",
       "        [0.3562, 0.1736, 0.4430, 0.3709, 0.3786, 0.2883, 0.0440, 0.4629, 0.1840,\n",
       "         0.5345, 0.0759, 0.8155, 0.1458, 0.6542, 0.9301, 0.5017, 0.0622, 0.5532,\n",
       "         0.1870, 0.8482, 0.1344, 0.2848, 0.3113, 0.0449, 0.2927, 0.0515, 0.4758,\n",
       "         0.9621],\n",
       "        [0.6153, 0.2388, 0.3310, 0.4295, 0.5945, 0.1166, 0.9960, 0.7236, 0.6831,\n",
       "         0.8744, 0.4640, 0.5804, 0.0639, 0.3633, 0.3443, 0.2289, 0.2871, 0.6178,\n",
       "         0.7783, 0.3151, 0.0388, 0.1668, 0.5136, 0.9216, 0.1864, 0.3440, 0.8600,\n",
       "         0.0582],\n",
       "        [0.9265, 0.0871, 0.6162, 0.1035, 0.2663, 0.7620, 0.5075, 0.7737, 0.5655,\n",
       "         0.9936, 0.2039, 0.1496, 0.2133, 0.1513, 0.8971, 0.8088, 0.8361, 0.8554,\n",
       "         0.2786, 0.8229, 0.7954, 0.4307, 0.1794, 0.3880, 0.8948, 0.5911, 0.0458,\n",
       "         0.9745],\n",
       "        [0.5905, 0.9806, 0.0363, 0.8863, 0.5683, 0.3342, 0.4806, 0.2420, 0.5786,\n",
       "         0.9533, 0.7104, 0.4904, 0.4281, 0.7623, 0.3614, 0.6907, 0.9303, 0.0652,\n",
       "         0.8770, 0.4550, 0.8163, 0.7519, 0.2538, 0.0077, 0.1524, 0.5775, 0.3356,\n",
       "         0.5046],\n",
       "        [0.5013, 0.9591, 0.8705, 0.3594, 0.7265, 0.5482, 0.7760, 0.5867, 0.7230,\n",
       "         0.6638, 0.8675, 0.4286, 0.7636, 0.1519, 0.4066, 0.5075, 0.6889, 0.2054,\n",
       "         0.6061, 0.9561, 0.7589, 0.5619, 0.0881, 0.8399, 0.4135, 0.2405, 0.6255,\n",
       "         0.9937],\n",
       "        [0.0040, 0.8130, 0.6589, 0.4263, 0.1415, 0.8306, 0.5838, 0.1727, 0.1757,\n",
       "         0.6423, 0.4721, 0.3168, 0.6076, 0.8462, 0.3600, 0.9114, 0.1492, 0.3370,\n",
       "         0.4543, 0.1861, 0.1220, 0.3564, 0.8086, 0.5510, 0.5948, 0.2599, 0.2297,\n",
       "         0.9780],\n",
       "        [0.2462, 0.2828, 0.6067, 0.5604, 0.8112, 0.0726, 0.2428, 0.2999, 0.7266,\n",
       "         0.3745, 0.2472, 0.9995, 0.2788, 0.1162, 0.1867, 0.5177, 0.0928, 0.0447,\n",
       "         0.2392, 0.9939, 0.8790, 0.6598, 0.6032, 0.4846, 0.7059, 0.3424, 0.4467,\n",
       "         0.5236],\n",
       "        [0.8731, 0.2744, 0.3484, 0.9120, 0.1618, 0.9955, 0.1836, 0.6931, 0.4342,\n",
       "         0.2333, 0.9065, 0.3313, 0.6565, 0.8277, 0.0630, 0.0804, 0.1922, 0.2073,\n",
       "         0.0570, 0.6805, 0.0199, 0.9038, 0.1107, 0.9266, 0.7713, 0.2639, 0.9964,\n",
       "         0.1410],\n",
       "        [0.3751, 0.1746, 0.3419, 0.7238, 0.7322, 0.3137, 0.2707, 0.0452, 0.8910,\n",
       "         0.7254, 0.9743, 0.9063, 0.8662, 0.2818, 0.2990, 0.8488, 0.5548, 0.3193,\n",
       "         0.4958, 0.4820, 0.8543, 0.1690, 0.0104, 0.8577, 0.3417, 0.8071, 0.0738,\n",
       "         0.5137],\n",
       "        [0.8219, 0.9033, 0.5070, 0.4347, 0.2281, 0.8098, 0.8309, 0.2967, 0.3706,\n",
       "         0.7815, 0.2568, 0.0690, 0.2910, 0.5591, 0.6185, 0.3026, 0.4588, 0.8550,\n",
       "         0.4015, 0.7052, 0.2534, 0.6733, 0.8236, 0.2560, 0.7115, 0.8373, 0.3222,\n",
       "         0.3435],\n",
       "        [0.4285, 0.6405, 0.3255, 0.4378, 0.0164, 0.2354, 0.4859, 0.3561, 0.7949,\n",
       "         0.7129, 0.8520, 0.0103, 0.5902, 0.3109, 0.3259, 0.7969, 0.2112, 0.6449,\n",
       "         0.2699, 0.0212, 0.8530, 0.7097, 0.6930, 0.2376, 0.9819, 0.4137, 0.5738,\n",
       "         0.7224],\n",
       "        [0.3409, 0.2651, 0.1766, 0.1421, 0.5038, 0.6282, 0.2372, 0.8651, 0.9559,\n",
       "         0.9441, 0.4141, 0.3871, 0.0902, 0.2359, 0.2885, 0.0425, 0.4976, 0.9152,\n",
       "         0.6299, 0.7850, 0.7682, 0.1119, 0.9710, 0.8004, 0.7812, 0.4941, 0.4833,\n",
       "         0.9343]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8285e7b-7c29-4413-9010-3105304899b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(second_image, cmap = 'gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7276d6c-a06b-4d8a-bbd5-1418df757004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (hidden_layer): Linear(in_features=10, out_features=64, bias=True)\n",
      "  (output_layer): Linear(in_features=64, out_features=2, bias=True)\n",
      "  (activation): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self,input_size):\n",
    "        super(MLP,self).__init__()\n",
    "        self.hidden_layer = nn.Linear(input_size,64)\n",
    "        self.output_layer = nn.Linear(64,2)\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.activation(self.hidden_layer(x))\n",
    "        return self.output_layer(x)\n",
    "\n",
    "model = MLP(10)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6887f7e2-9c30-4665-9c72-499afe0ebcde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0713,  0.1476], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.forward(torch.rand(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b6ef91-5cae-494d-b34e-a83a9d91e656",
   "metadata": {},
   "source": [
    "##### Try yourself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "865c8be5-aa3e-42d3-80b7-c2c4a3ae5b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (hidden_layer): Linear(in_features=5, out_features=30, bias=True)\n",
      "  (out_layer): Linear(in_features=30, out_features=2, bias=True)\n",
      "  (activation): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self,input_size):\n",
    "        super(MLP,self).__init__()\n",
    "        self.hidden_layer = nn.Linear(input_size,30)\n",
    "        self.out_layer = nn.Linear(30,2)\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.activation(self.hidden_layer(x))\n",
    "        return self.out_layer(x)\n",
    "\n",
    "model = MLP(5)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f24961a-1b4a-4499-8072-b89fa1f6116d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0587, -0.1345], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.forward(torch.rand(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ed101a1-6b15-4fc7-984a-930649a46f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([1., 1.]), tensor([2.]))\n",
      "(tensor([1., 2.]), tensor([3.]))\n",
      "(tensor([1., 3.]), tensor([4.]))\n",
      "(tensor([1., 4.]), tensor([5.]))\n",
      "(tensor([1., 5.]), tensor([6.]))\n",
      "(tensor([1., 6.]), tensor([7.]))\n",
      "(tensor([1., 7.]), tensor([8.]))\n",
      "(tensor([1., 8.]), tensor([9.]))\n",
      "(tensor([1., 9.]), tensor([10.]))\n",
      "(tensor([ 1., 10.]), tensor([11.]))\n",
      "(tensor([ 1., 11.]), tensor([12.]))\n",
      "(tensor([ 1., 12.]), tensor([13.]))\n",
      "(tensor([ 1., 13.]), tensor([14.]))\n",
      "(tensor([ 1., 14.]), tensor([15.]))\n",
      "(tensor([ 1., 15.]), tensor([16.]))\n",
      "(tensor([ 1., 16.]), tensor([17.]))\n",
      "(tensor([ 1., 17.]), tensor([18.]))\n",
      "(tensor([ 1., 18.]), tensor([19.]))\n",
      "(tensor([ 1., 19.]), tensor([20.]))\n",
      "(tensor([ 1., 20.]), tensor([21.]))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class NumberSumDataset(Dataset):\n",
    "    def __init__(self, data_range=(1, 10)):\n",
    "        self.numbers = list(range(data_range[0], data_range[1]))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        number1 = float(self.numbers[index // len(self.numbers)])\n",
    "        number2 = float(self.numbers[index % len(self.numbers)])\n",
    "        return torch.tensor([number1, number2]), torch.tensor([number1 + number2])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.numbers) ** 2\n",
    "\n",
    "dataset = NumberSumDataset(data_range=(1, 100))\n",
    "\n",
    "for i in range(20):\n",
    "    print(dataset[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "435a18a0-dae4-42a5-9540-f66a1109ec65",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.hidden_layer = nn.Linear(input_size, 128)\n",
    "        self.output_layer = nn.Linear(128, 1)\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.hidden_layer(x))\n",
    "        return self.output_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98b7fb79-502c-4da6-add1-a5dcb90027f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Sum of Batch Losses = 191.19571\n",
      "Epoch 1: Sum of Batch Losses = 58.54060\n",
      "Epoch 2: Sum of Batch Losses = 5.88175\n",
      "Epoch 3: Sum of Batch Losses = 1.11041\n",
      "Epoch 4: Sum of Batch Losses = 0.82065\n",
      "Epoch 5: Sum of Batch Losses = 0.49825\n",
      "Epoch 6: Sum of Batch Losses = 0.25232\n",
      "Epoch 7: Sum of Batch Losses = 0.08725\n",
      "Epoch 8: Sum of Batch Losses = 0.08428\n",
      "Epoch 9: Sum of Batch Losses = 0.05697\n",
      "Epoch 10: Sum of Batch Losses = 0.03579\n",
      "Epoch 11: Sum of Batch Losses = 0.04387\n",
      "Epoch 12: Sum of Batch Losses = 0.04486\n",
      "Epoch 13: Sum of Batch Losses = 0.03370\n",
      "Epoch 14: Sum of Batch Losses = 0.04457\n",
      "Epoch 15: Sum of Batch Losses = 0.03097\n",
      "Epoch 16: Sum of Batch Losses = 0.02117\n",
      "Epoch 17: Sum of Batch Losses = 0.02440\n",
      "Epoch 18: Sum of Batch Losses = 0.02488\n",
      "Epoch 19: Sum of Batch Losses = 0.01985\n",
      "Epoch 20: Sum of Batch Losses = 0.02263\n",
      "Epoch 21: Sum of Batch Losses = 0.01807\n",
      "Epoch 22: Sum of Batch Losses = 0.01632\n",
      "Epoch 23: Sum of Batch Losses = 0.01683\n",
      "Epoch 24: Sum of Batch Losses = 0.01605\n",
      "Epoch 25: Sum of Batch Losses = 0.01460\n",
      "Epoch 26: Sum of Batch Losses = 0.00762\n",
      "Epoch 27: Sum of Batch Losses = 0.00958\n",
      "Epoch 28: Sum of Batch Losses = 0.00971\n",
      "Epoch 29: Sum of Batch Losses = 0.00763\n",
      "Epoch 30: Sum of Batch Losses = 0.00843\n",
      "Epoch 31: Sum of Batch Losses = 0.00548\n",
      "Epoch 32: Sum of Batch Losses = 0.01013\n",
      "Epoch 33: Sum of Batch Losses = 0.00671\n",
      "Epoch 34: Sum of Batch Losses = 0.00528\n",
      "Epoch 35: Sum of Batch Losses = 0.00654\n",
      "Epoch 36: Sum of Batch Losses = 0.00589\n",
      "Epoch 37: Sum of Batch Losses = 0.00527\n",
      "Epoch 38: Sum of Batch Losses = 0.00514\n",
      "Epoch 39: Sum of Batch Losses = 0.00619\n",
      "Epoch 40: Sum of Batch Losses = 0.00486\n",
      "Epoch 41: Sum of Batch Losses = 0.00511\n",
      "Epoch 42: Sum of Batch Losses = 0.00472\n",
      "Epoch 43: Sum of Batch Losses = 0.00333\n",
      "Epoch 44: Sum of Batch Losses = 0.00311\n",
      "Epoch 45: Sum of Batch Losses = 0.00318\n",
      "Epoch 46: Sum of Batch Losses = 0.00337\n",
      "Epoch 47: Sum of Batch Losses = 0.00386\n",
      "Epoch 48: Sum of Batch Losses = 0.00292\n",
      "Epoch 49: Sum of Batch Losses = 0.00262\n"
     ]
    }
   ],
   "source": [
    "dataset = NumberSumDataset(data_range=(0, 100))\n",
    "dataloader = DataLoader(dataset, batch_size=100, shuffle=True)\n",
    "model = MLP(input_size=2)\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(50):\n",
    "    loss = 0.0\n",
    "    for number_pairs, sums in dataloader:  # Iterate over the batches\n",
    "        predictions = model(number_pairs)  # Compute the model output\n",
    "        loss = loss_function(predictions, sums)  # Compute the loss\n",
    "        loss.backward()  # Perform backpropagation\n",
    "        optimizer.step()  # Update the parameters\n",
    "        optimizer.zero_grad()  # Zero the gradients\n",
    "\n",
    "        loss += loss.item()  # Add the loss for all batches\n",
    "\n",
    "    # Print the loss for this epoch\n",
    "    print(\"Epoch {}: Sum of Batch Losses = {:.5f}\".format(epoch, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9073dff1-fe88-4182-bb61-d1beccf7c994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.0050], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.tensor([0.0,3.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "028a8435-7878-4d90-b51d-43f8822c83c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8116ba36-7a09-40d6-8a3a-65eb6941045d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Obtaining dependency information for torch from https://files.pythonhosted.org/packages/5c/01/5ab75f138bf32d7a69df61e4997e24eccad87cc009f5fb7e2a31af8a4036/torch-2.2.2-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading torch-2.2.2-cp311-cp311-win_amd64.whl.metadata (26 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\mayuo\\anaconda3\\lib\\site-packages (from torch) (3.9.0)\n",
      "Collecting typing-extensions>=4.8.0 (from torch)\n",
      "  Obtaining dependency information for typing-extensions>=4.8.0 from https://files.pythonhosted.org/packages/f9/de/dc04a3ea60b22624b51c703a84bbe0184abcd1d0b9bc8074b5d6b7ab90bb/typing_extensions-4.10.0-py3-none-any.whl.metadata\n",
      "  Downloading typing_extensions-4.10.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: sympy in c:\\users\\mayuo\\anaconda3\\lib\\site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\mayuo\\anaconda3\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\mayuo\\anaconda3\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\mayuo\\anaconda3\\lib\\site-packages (from torch) (2023.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\mayuo\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\mayuo\\anaconda3\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Downloading torch-2.2.2-cp311-cp311-win_amd64.whl (198.6 MB)\n",
      "   ---------------------------------------- 0.0/198.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/198.6 MB 4.3 MB/s eta 0:00:47\n",
      "   ---------------------------------------- 0.5/198.6 MB 6.7 MB/s eta 0:00:30\n",
      "   ---------------------------------------- 0.9/198.6 MB 7.1 MB/s eta 0:00:28\n",
      "   ---------------------------------------- 1.2/198.6 MB 7.0 MB/s eta 0:00:29\n",
      "   ---------------------------------------- 1.6/198.6 MB 7.1 MB/s eta 0:00:28\n",
      "   ---------------------------------------- 2.1/198.6 MB 7.7 MB/s eta 0:00:26\n",
      "   ---------------------------------------- 2.5/198.6 MB 7.8 MB/s eta 0:00:26\n",
      "    --------------------------------------- 2.9/198.6 MB 8.2 MB/s eta 0:00:24\n",
      "    --------------------------------------- 3.4/198.6 MB 8.4 MB/s eta 0:00:24\n",
      "    --------------------------------------- 3.8/198.6 MB 8.7 MB/s eta 0:00:23\n",
      "    --------------------------------------- 4.4/198.6 MB 8.7 MB/s eta 0:00:23\n",
      "    --------------------------------------- 4.7/198.6 MB 8.6 MB/s eta 0:00:23\n",
      "   - -------------------------------------- 5.2/198.6 MB 9.0 MB/s eta 0:00:22\n",
      "   - -------------------------------------- 5.5/198.6 MB 8.8 MB/s eta 0:00:22\n",
      "   - -------------------------------------- 6.0/198.6 MB 8.7 MB/s eta 0:00:23\n",
      "   - -------------------------------------- 6.4/198.6 MB 8.9 MB/s eta 0:00:22\n",
      "   - -------------------------------------- 7.0/198.6 MB 9.2 MB/s eta 0:00:21\n",
      "   - -------------------------------------- 7.6/198.6 MB 9.1 MB/s eta 0:00:21\n",
      "   - -------------------------------------- 7.9/198.6 MB 9.2 MB/s eta 0:00:21\n",
      "   - -------------------------------------- 8.4/198.6 MB 9.2 MB/s eta 0:00:21\n",
      "   - -------------------------------------- 8.7/198.6 MB 9.1 MB/s eta 0:00:21\n",
      "   - -------------------------------------- 9.1/198.6 MB 9.1 MB/s eta 0:00:21\n",
      "   - -------------------------------------- 9.5/198.6 MB 9.1 MB/s eta 0:00:21\n",
      "   -- ------------------------------------- 10.0/198.6 MB 9.1 MB/s eta 0:00:21\n",
      "   -- ------------------------------------- 10.5/198.6 MB 9.4 MB/s eta 0:00:21\n",
      "   -- ------------------------------------- 10.9/198.6 MB 9.4 MB/s eta 0:00:21\n",
      "   -- ------------------------------------- 11.4/198.6 MB 9.5 MB/s eta 0:00:20\n",
      "   -- ------------------------------------- 11.9/198.6 MB 9.6 MB/s eta 0:00:20\n",
      "   -- ------------------------------------- 12.3/198.6 MB 9.6 MB/s eta 0:00:20\n",
      "   -- ------------------------------------- 12.6/198.6 MB 9.6 MB/s eta 0:00:20\n",
      "   -- ------------------------------------- 13.2/198.6 MB 9.6 MB/s eta 0:00:20\n",
      "   -- ------------------------------------- 13.2/198.6 MB 9.6 MB/s eta 0:00:20\n",
      "   -- ------------------------------------- 13.7/198.6 MB 9.4 MB/s eta 0:00:20\n",
      "   -- ------------------------------------- 13.7/198.6 MB 9.4 MB/s eta 0:00:20\n",
      "   -- ------------------------------------- 13.7/198.6 MB 9.4 MB/s eta 0:00:20\n",
      "   -- ------------------------------------- 13.7/198.6 MB 8.3 MB/s eta 0:00:23\n",
      "   -- ------------------------------------- 13.8/198.6 MB 8.0 MB/s eta 0:00:24\n",
      "   -- ------------------------------------- 14.0/198.6 MB 7.8 MB/s eta 0:00:24\n",
      "   -- ------------------------------------- 14.1/198.6 MB 7.7 MB/s eta 0:00:24\n",
      "   -- ------------------------------------- 14.4/198.6 MB 7.4 MB/s eta 0:00:25\n",
      "   -- ------------------------------------- 14.4/198.6 MB 7.3 MB/s eta 0:00:26\n",
      "   -- ------------------------------------- 14.5/198.6 MB 7.1 MB/s eta 0:00:26\n",
      "   -- ------------------------------------- 14.6/198.6 MB 7.0 MB/s eta 0:00:27\n",
      "   -- ------------------------------------- 14.9/198.6 MB 6.8 MB/s eta 0:00:27\n",
      "   --- ------------------------------------ 14.9/198.6 MB 6.7 MB/s eta 0:00:28\n",
      "   --- ------------------------------------ 15.2/198.6 MB 6.6 MB/s eta 0:00:28\n",
      "   --- ------------------------------------ 15.3/198.6 MB 6.4 MB/s eta 0:00:29\n",
      "   --- ------------------------------------ 15.3/198.6 MB 6.2 MB/s eta 0:00:30\n",
      "   --- ------------------------------------ 15.4/198.6 MB 6.1 MB/s eta 0:00:31\n",
      "   --- ------------------------------------ 15.9/198.6 MB 6.2 MB/s eta 0:00:30\n",
      "   --- ------------------------------------ 16.3/198.6 MB 6.1 MB/s eta 0:00:30\n",
      "   --- ------------------------------------ 16.7/198.6 MB 6.2 MB/s eta 0:00:30\n",
      "   --- ------------------------------------ 16.9/198.6 MB 6.1 MB/s eta 0:00:30\n",
      "   --- ------------------------------------ 17.1/198.6 MB 6.0 MB/s eta 0:00:31\n",
      "   --- ------------------------------------ 17.5/198.6 MB 5.9 MB/s eta 0:00:31\n",
      "   --- ------------------------------------ 17.9/198.6 MB 5.8 MB/s eta 0:00:31\n",
      "   --- ------------------------------------ 17.9/198.6 MB 5.8 MB/s eta 0:00:31\n",
      "   --- ------------------------------------ 18.2/198.6 MB 5.7 MB/s eta 0:00:32\n",
      "   --- ------------------------------------ 18.5/198.6 MB 5.7 MB/s eta 0:00:32\n",
      "   --- ------------------------------------ 19.1/198.6 MB 5.7 MB/s eta 0:00:32\n",
      "   --- ------------------------------------ 19.2/198.6 MB 5.6 MB/s eta 0:00:33\n",
      "   --- ------------------------------------ 19.7/198.6 MB 5.6 MB/s eta 0:00:32\n",
      "   ---- ----------------------------------- 20.0/198.6 MB 5.6 MB/s eta 0:00:32\n",
      "   ---- ----------------------------------- 20.5/198.6 MB 5.6 MB/s eta 0:00:32\n",
      "   ---- ----------------------------------- 20.8/198.6 MB 5.5 MB/s eta 0:00:33\n",
      "   ---- ----------------------------------- 20.9/198.6 MB 5.5 MB/s eta 0:00:33\n",
      "   ---- ----------------------------------- 21.0/198.6 MB 5.4 MB/s eta 0:00:33\n",
      "   ---- ----------------------------------- 21.1/198.6 MB 5.2 MB/s eta 0:00:34\n",
      "   ---- ----------------------------------- 21.3/198.6 MB 5.2 MB/s eta 0:00:35\n",
      "   ---- ----------------------------------- 21.4/198.6 MB 5.1 MB/s eta 0:00:35\n",
      "   ---- ----------------------------------- 21.7/198.6 MB 5.0 MB/s eta 0:00:36\n",
      "   ---- ----------------------------------- 21.9/198.6 MB 5.0 MB/s eta 0:00:36\n",
      "   ---- ----------------------------------- 22.2/198.6 MB 5.0 MB/s eta 0:00:36\n",
      "   ---- ----------------------------------- 22.4/198.6 MB 4.9 MB/s eta 0:00:37\n",
      "   ---- ----------------------------------- 22.7/198.6 MB 4.8 MB/s eta 0:00:37\n",
      "   ---- ----------------------------------- 23.1/198.6 MB 4.8 MB/s eta 0:00:37\n",
      "   ---- ----------------------------------- 23.5/198.6 MB 5.0 MB/s eta 0:00:36\n",
      "   ---- ----------------------------------- 23.6/198.6 MB 4.9 MB/s eta 0:00:36\n",
      "   ---- ----------------------------------- 23.9/198.6 MB 4.7 MB/s eta 0:00:37\n",
      "   ---- ----------------------------------- 24.1/198.6 MB 5.2 MB/s eta 0:00:34\n",
      "   ---- ----------------------------------- 24.1/198.6 MB 5.1 MB/s eta 0:00:35\n",
      "   ---- ----------------------------------- 24.2/198.6 MB 5.0 MB/s eta 0:00:35\n",
      "   ---- ----------------------------------- 24.5/198.6 MB 5.1 MB/s eta 0:00:35\n",
      "   ----- ---------------------------------- 24.8/198.6 MB 5.3 MB/s eta 0:00:33\n",
      "   ----- ---------------------------------- 25.1/198.6 MB 5.5 MB/s eta 0:00:32\n",
      "   ----- ---------------------------------- 25.6/198.6 MB 5.7 MB/s eta 0:00:31\n",
      "   ----- ---------------------------------- 26.0/198.6 MB 5.9 MB/s eta 0:00:30\n",
      "   ----- ---------------------------------- 26.4/198.6 MB 5.9 MB/s eta 0:00:30\n",
      "   ----- ---------------------------------- 26.8/198.6 MB 5.9 MB/s eta 0:00:30\n",
      "   ----- ---------------------------------- 27.3/198.6 MB 6.1 MB/s eta 0:00:29\n",
      "   ----- ---------------------------------- 27.8/198.6 MB 6.1 MB/s eta 0:00:28\n",
      "   ----- ---------------------------------- 28.2/198.6 MB 6.4 MB/s eta 0:00:27\n",
      "   ----- ---------------------------------- 28.5/198.6 MB 6.3 MB/s eta 0:00:28\n",
      "   ----- ---------------------------------- 29.0/198.6 MB 6.4 MB/s eta 0:00:27\n",
      "   ----- ---------------------------------- 29.4/198.6 MB 6.4 MB/s eta 0:00:27\n",
      "   ------ --------------------------------- 29.9/198.6 MB 6.4 MB/s eta 0:00:27\n",
      "   ------ --------------------------------- 30.4/198.6 MB 6.5 MB/s eta 0:00:26\n",
      "   ------ --------------------------------- 30.8/198.6 MB 6.5 MB/s eta 0:00:26\n",
      "   ------ --------------------------------- 31.3/198.6 MB 6.9 MB/s eta 0:00:25\n",
      "   ------ --------------------------------- 31.7/198.6 MB 7.3 MB/s eta 0:00:23\n",
      "   ------ --------------------------------- 32.1/198.6 MB 7.5 MB/s eta 0:00:23\n",
      "   ------ --------------------------------- 32.6/198.6 MB 7.8 MB/s eta 0:00:22\n",
      "   ------ --------------------------------- 33.2/198.6 MB 8.0 MB/s eta 0:00:21\n",
      "   ------ --------------------------------- 33.7/198.6 MB 8.2 MB/s eta 0:00:21\n",
      "   ------ --------------------------------- 33.9/198.6 MB 8.2 MB/s eta 0:00:21\n",
      "   ------ --------------------------------- 34.4/198.6 MB 8.5 MB/s eta 0:00:20\n",
      "   ------ --------------------------------- 34.6/198.6 MB 9.0 MB/s eta 0:00:19\n",
      "   ------- -------------------------------- 35.1/198.6 MB 9.2 MB/s eta 0:00:18\n",
      "   ------- -------------------------------- 35.5/198.6 MB 9.1 MB/s eta 0:00:18\n",
      "   ------- -------------------------------- 36.0/198.6 MB 9.2 MB/s eta 0:00:18\n",
      "   ------- -------------------------------- 36.4/198.6 MB 9.2 MB/s eta 0:00:18\n",
      "   ------- -------------------------------- 36.6/198.6 MB 9.2 MB/s eta 0:00:18\n",
      "   ------- -------------------------------- 37.0/198.6 MB 9.1 MB/s eta 0:00:18\n",
      "   ------- -------------------------------- 37.4/198.6 MB 9.1 MB/s eta 0:00:18\n",
      "   ------- -------------------------------- 37.5/198.6 MB 9.1 MB/s eta 0:00:18\n",
      "   ------- -------------------------------- 37.5/198.6 MB 9.1 MB/s eta 0:00:18\n",
      "   ------- -------------------------------- 37.5/198.6 MB 9.1 MB/s eta 0:00:18\n",
      "   ------- -------------------------------- 37.5/198.6 MB 9.1 MB/s eta 0:00:18\n",
      "   ------- -------------------------------- 37.5/198.6 MB 9.1 MB/s eta 0:00:18\n",
      "   ------- -------------------------------- 37.5/198.6 MB 9.1 MB/s eta 0:00:18\n",
      "   ------- -------------------------------- 37.7/198.6 MB 7.2 MB/s eta 0:00:23\n",
      "   ------- -------------------------------- 38.0/198.6 MB 7.1 MB/s eta 0:00:23\n",
      "   ------- -------------------------------- 38.6/198.6 MB 7.2 MB/s eta 0:00:23\n",
      "   ------- -------------------------------- 38.9/198.6 MB 7.2 MB/s eta 0:00:23\n",
      "   ------- -------------------------------- 39.3/198.6 MB 7.1 MB/s eta 0:00:23\n",
      "   -------- ------------------------------- 39.7/198.6 MB 7.1 MB/s eta 0:00:23\n",
      "   -------- ------------------------------- 40.2/198.6 MB 7.2 MB/s eta 0:00:23\n",
      "   -------- ------------------------------- 40.7/198.6 MB 7.1 MB/s eta 0:00:23\n",
      "   -------- ------------------------------- 41.1/198.6 MB 7.1 MB/s eta 0:00:23\n",
      "   -------- ------------------------------- 41.6/198.6 MB 7.2 MB/s eta 0:00:22\n",
      "   -------- ------------------------------- 42.1/198.6 MB 7.1 MB/s eta 0:00:22\n",
      "   -------- ------------------------------- 42.5/198.6 MB 7.1 MB/s eta 0:00:22\n",
      "   -------- ------------------------------- 42.9/198.6 MB 7.1 MB/s eta 0:00:22\n",
      "   -------- ------------------------------- 43.4/198.6 MB 7.0 MB/s eta 0:00:23\n",
      "   -------- ------------------------------- 43.7/198.6 MB 7.0 MB/s eta 0:00:23\n",
      "   -------- ------------------------------- 44.1/198.6 MB 7.1 MB/s eta 0:00:22\n",
      "   -------- ------------------------------- 44.5/198.6 MB 7.0 MB/s eta 0:00:22\n",
      "   --------- ------------------------------ 44.9/198.6 MB 7.1 MB/s eta 0:00:22\n",
      "   --------- ------------------------------ 45.4/198.6 MB 7.1 MB/s eta 0:00:22\n",
      "   --------- ------------------------------ 45.8/198.6 MB 7.1 MB/s eta 0:00:22\n",
      "   --------- ------------------------------ 46.2/198.6 MB 7.0 MB/s eta 0:00:22\n",
      "   --------- ------------------------------ 46.5/198.6 MB 7.0 MB/s eta 0:00:22\n",
      "   --------- ------------------------------ 46.9/198.6 MB 7.0 MB/s eta 0:00:22\n",
      "   --------- ------------------------------ 47.1/198.6 MB 7.0 MB/s eta 0:00:22\n",
      "   --------- ------------------------------ 47.5/198.6 MB 7.0 MB/s eta 0:00:22\n",
      "   --------- ------------------------------ 48.0/198.6 MB 8.8 MB/s eta 0:00:18\n",
      "   --------- ------------------------------ 48.5/198.6 MB 8.8 MB/s eta 0:00:17\n",
      "   --------- ------------------------------ 48.8/198.6 MB 8.7 MB/s eta 0:00:18\n",
      "   --------- ------------------------------ 49.2/198.6 MB 8.7 MB/s eta 0:00:18\n",
      "   --------- ------------------------------ 49.4/198.6 MB 8.7 MB/s eta 0:00:18\n",
      "   ---------- ----------------------------- 50.0/198.6 MB 8.7 MB/s eta 0:00:18\n",
      "   ---------- ----------------------------- 50.5/198.6 MB 8.7 MB/s eta 0:00:17\n",
      "   ---------- ----------------------------- 50.7/198.6 MB 8.6 MB/s eta 0:00:18\n",
      "   ---------- ----------------------------- 51.2/198.6 MB 8.6 MB/s eta 0:00:18\n",
      "   ---------- ----------------------------- 51.8/198.6 MB 8.7 MB/s eta 0:00:17\n",
      "   ---------- ----------------------------- 52.3/198.6 MB 8.8 MB/s eta 0:00:17\n",
      "   ---------- ----------------------------- 52.9/198.6 MB 9.0 MB/s eta 0:00:17\n",
      "   ---------- ----------------------------- 53.3/198.6 MB 9.1 MB/s eta 0:00:16\n",
      "   ---------- ----------------------------- 53.9/198.6 MB 9.2 MB/s eta 0:00:16\n",
      "   ---------- ----------------------------- 54.3/198.6 MB 9.1 MB/s eta 0:00:16\n",
      "   ---------- ----------------------------- 54.5/198.6 MB 9.0 MB/s eta 0:00:17\n",
      "   ----------- ---------------------------- 55.0/198.6 MB 9.2 MB/s eta 0:00:16\n",
      "   ----------- ---------------------------- 55.7/198.6 MB 9.2 MB/s eta 0:00:16\n",
      "   ----------- ---------------------------- 56.0/198.6 MB 9.1 MB/s eta 0:00:16\n",
      "   ----------- ---------------------------- 56.4/198.6 MB 9.1 MB/s eta 0:00:16\n",
      "   ----------- ---------------------------- 56.9/198.6 MB 9.4 MB/s eta 0:00:16\n",
      "   ----------- ---------------------------- 57.3/198.6 MB 9.6 MB/s eta 0:00:15\n",
      "   ----------- ---------------------------- 57.6/198.6 MB 9.6 MB/s eta 0:00:15\n",
      "   ----------- ---------------------------- 58.1/198.6 MB 9.5 MB/s eta 0:00:15\n",
      "   ----------- ---------------------------- 58.6/198.6 MB 9.6 MB/s eta 0:00:15\n",
      "   ----------- ---------------------------- 58.9/198.6 MB 9.5 MB/s eta 0:00:15\n",
      "   ----------- ---------------------------- 59.2/198.6 MB 9.5 MB/s eta 0:00:15\n",
      "   ------------ --------------------------- 59.6/198.6 MB 9.6 MB/s eta 0:00:15\n",
      "   ------------ --------------------------- 60.3/198.6 MB 9.6 MB/s eta 0:00:15\n",
      "   ------------ --------------------------- 60.6/198.6 MB 9.5 MB/s eta 0:00:15\n",
      "   ------------ --------------------------- 61.0/198.6 MB 9.8 MB/s eta 0:00:15\n",
      "   ------------ --------------------------- 61.5/198.6 MB 9.6 MB/s eta 0:00:15\n",
      "   ------------ --------------------------- 61.9/198.6 MB 9.6 MB/s eta 0:00:15\n",
      "   ------------ --------------------------- 62.1/198.6 MB 9.4 MB/s eta 0:00:15\n",
      "   ------------ --------------------------- 62.2/198.6 MB 9.1 MB/s eta 0:00:15\n",
      "   ------------ --------------------------- 62.5/198.6 MB 8.8 MB/s eta 0:00:16\n",
      "   ------------ --------------------------- 63.0/198.6 MB 8.7 MB/s eta 0:00:16\n",
      "   ------------ --------------------------- 63.4/198.6 MB 8.6 MB/s eta 0:00:16\n",
      "   ------------ --------------------------- 63.9/198.6 MB 8.6 MB/s eta 0:00:16\n",
      "   ------------ --------------------------- 64.4/198.6 MB 8.7 MB/s eta 0:00:16\n",
      "   ------------- -------------------------- 64.8/198.6 MB 8.8 MB/s eta 0:00:16\n",
      "   ------------- -------------------------- 65.3/198.6 MB 8.8 MB/s eta 0:00:16\n",
      "   ------------- -------------------------- 65.7/198.6 MB 8.7 MB/s eta 0:00:16\n",
      "   ------------- -------------------------- 66.3/198.6 MB 8.8 MB/s eta 0:00:15\n",
      "   ------------- -------------------------- 66.8/198.6 MB 9.0 MB/s eta 0:00:15\n",
      "   ------------- -------------------------- 67.3/198.6 MB 9.0 MB/s eta 0:00:15\n",
      "   ------------- -------------------------- 67.9/198.6 MB 9.1 MB/s eta 0:00:15\n",
      "   ------------- -------------------------- 68.3/198.6 MB 9.1 MB/s eta 0:00:15\n",
      "   ------------- -------------------------- 68.7/198.6 MB 9.0 MB/s eta 0:00:15\n",
      "   ------------- -------------------------- 69.2/198.6 MB 9.2 MB/s eta 0:00:15\n",
      "   -------------- ------------------------- 69.6/198.6 MB 9.2 MB/s eta 0:00:14\n",
      "   -------------- ------------------------- 69.9/198.6 MB 9.2 MB/s eta 0:00:14\n",
      "   -------------- ------------------------- 70.6/198.6 MB 9.2 MB/s eta 0:00:14\n",
      "   -------------- ------------------------- 71.0/198.6 MB 9.2 MB/s eta 0:00:14\n",
      "   -------------- ------------------------- 71.5/198.6 MB 9.4 MB/s eta 0:00:14\n",
      "   -------------- ------------------------- 72.0/198.6 MB 9.4 MB/s eta 0:00:14\n",
      "   -------------- ------------------------- 72.4/198.6 MB 9.9 MB/s eta 0:00:13\n",
      "   -------------- ------------------------- 72.9/198.6 MB 10.4 MB/s eta 0:00:13\n",
      "   -------------- ------------------------- 73.4/198.6 MB 10.4 MB/s eta 0:00:13\n",
      "   -------------- ------------------------- 73.9/198.6 MB 10.2 MB/s eta 0:00:13\n",
      "   -------------- ------------------------- 74.4/198.6 MB 10.4 MB/s eta 0:00:12\n",
      "   --------------- ------------------------ 74.8/198.6 MB 10.4 MB/s eta 0:00:12\n",
      "   --------------- ------------------------ 75.2/198.6 MB 10.2 MB/s eta 0:00:13\n",
      "   --------------- ------------------------ 75.8/198.6 MB 10.4 MB/s eta 0:00:12\n",
      "   --------------- ------------------------ 76.1/198.6 MB 10.2 MB/s eta 0:00:12\n",
      "   --------------- ------------------------ 76.5/198.6 MB 10.1 MB/s eta 0:00:13\n",
      "   --------------- ------------------------ 77.0/198.6 MB 10.1 MB/s eta 0:00:13\n",
      "   --------------- ------------------------ 77.5/198.6 MB 10.1 MB/s eta 0:00:13\n",
      "   --------------- ------------------------ 77.9/198.6 MB 9.9 MB/s eta 0:00:13\n",
      "   --------------- ------------------------ 78.4/198.6 MB 9.9 MB/s eta 0:00:13\n",
      "   --------------- ------------------------ 78.8/198.6 MB 9.9 MB/s eta 0:00:13\n",
      "   --------------- ------------------------ 79.4/198.6 MB 10.1 MB/s eta 0:00:12\n",
      "   ---------------- ----------------------- 79.8/198.6 MB 9.9 MB/s eta 0:00:12\n",
      "   ---------------- ----------------------- 80.4/198.6 MB 10.1 MB/s eta 0:00:12\n",
      "   ---------------- ----------------------- 80.8/198.6 MB 10.2 MB/s eta 0:00:12\n",
      "   ---------------- ----------------------- 81.0/198.6 MB 9.9 MB/s eta 0:00:12\n",
      "   ---------------- ----------------------- 81.2/198.6 MB 9.5 MB/s eta 0:00:13\n",
      "   ---------------- ----------------------- 81.5/198.6 MB 9.4 MB/s eta 0:00:13\n",
      "   ---------------- ----------------------- 82.0/198.6 MB 9.4 MB/s eta 0:00:13\n",
      "   ---------------- ----------------------- 82.5/198.6 MB 9.4 MB/s eta 0:00:13\n",
      "   ---------------- ----------------------- 82.9/198.6 MB 9.4 MB/s eta 0:00:13\n",
      "   ---------------- ----------------------- 83.4/198.6 MB 9.4 MB/s eta 0:00:13\n",
      "   ---------------- ----------------------- 83.8/198.6 MB 9.4 MB/s eta 0:00:13\n",
      "   ----------------- ---------------------- 84.4/198.6 MB 9.4 MB/s eta 0:00:13\n",
      "   ----------------- ---------------------- 84.7/198.6 MB 9.5 MB/s eta 0:00:12\n",
      "   ----------------- ---------------------- 85.2/198.6 MB 9.2 MB/s eta 0:00:13\n",
      "   ----------------- ---------------------- 85.5/198.6 MB 9.2 MB/s eta 0:00:13\n",
      "   ----------------- ---------------------- 86.0/198.6 MB 9.1 MB/s eta 0:00:13\n",
      "   ----------------- ---------------------- 86.4/198.6 MB 9.2 MB/s eta 0:00:13\n",
      "   ----------------- ---------------------- 87.0/198.6 MB 9.2 MB/s eta 0:00:13\n",
      "   ----------------- ---------------------- 87.4/198.6 MB 9.5 MB/s eta 0:00:12\n",
      "   ----------------- ---------------------- 88.1/198.6 MB 9.6 MB/s eta 0:00:12\n",
      "   ----------------- ---------------------- 88.5/198.6 MB 9.4 MB/s eta 0:00:12\n",
      "   ----------------- ---------------------- 88.9/198.6 MB 9.4 MB/s eta 0:00:12\n",
      "   ----------------- ---------------------- 89.3/198.6 MB 9.2 MB/s eta 0:00:12\n",
      "   ------------------ --------------------- 89.7/198.6 MB 9.2 MB/s eta 0:00:12\n",
      "   ------------------ --------------------- 90.2/198.6 MB 9.2 MB/s eta 0:00:12\n",
      "   ------------------ --------------------- 90.6/198.6 MB 9.2 MB/s eta 0:00:12\n",
      "   ------------------ --------------------- 91.2/198.6 MB 9.4 MB/s eta 0:00:12\n",
      "   ------------------ --------------------- 91.6/198.6 MB 9.8 MB/s eta 0:00:11\n",
      "   ------------------ --------------------- 92.2/198.6 MB 10.1 MB/s eta 0:00:11\n",
      "   ------------------ --------------------- 92.7/198.6 MB 10.1 MB/s eta 0:00:11\n",
      "   ------------------ --------------------- 93.0/198.6 MB 9.9 MB/s eta 0:00:11\n",
      "   ------------------ --------------------- 93.4/198.6 MB 9.9 MB/s eta 0:00:11\n",
      "   ------------------ --------------------- 94.0/198.6 MB 10.1 MB/s eta 0:00:11\n",
      "   ------------------- -------------------- 94.5/198.6 MB 9.9 MB/s eta 0:00:11\n",
      "   ------------------- -------------------- 94.9/198.6 MB 9.8 MB/s eta 0:00:11\n",
      "   ------------------- -------------------- 95.3/198.6 MB 10.1 MB/s eta 0:00:11\n",
      "   ------------------- -------------------- 95.8/198.6 MB 10.1 MB/s eta 0:00:11\n",
      "   ------------------- -------------------- 96.0/198.6 MB 9.8 MB/s eta 0:00:11\n",
      "   ------------------- -------------------- 96.1/198.6 MB 9.5 MB/s eta 0:00:11\n",
      "   ------------------- -------------------- 96.4/198.6 MB 9.4 MB/s eta 0:00:11\n",
      "   ------------------- -------------------- 96.8/198.6 MB 9.2 MB/s eta 0:00:12\n",
      "   ------------------- -------------------- 97.2/198.6 MB 9.1 MB/s eta 0:00:12\n",
      "   ------------------- -------------------- 97.6/198.6 MB 9.1 MB/s eta 0:00:12\n",
      "   ------------------- -------------------- 97.8/198.6 MB 8.8 MB/s eta 0:00:12\n",
      "   ------------------- -------------------- 98.3/198.6 MB 8.7 MB/s eta 0:00:12\n",
      "   ------------------- -------------------- 98.4/198.6 MB 8.6 MB/s eta 0:00:12\n",
      "   ------------------- -------------------- 98.8/198.6 MB 8.5 MB/s eta 0:00:12\n",
      "   -------------------- ------------------- 99.3/198.6 MB 8.5 MB/s eta 0:00:12\n",
      "   -------------------- ------------------- 99.9/198.6 MB 8.7 MB/s eta 0:00:12\n",
      "   -------------------- ------------------- 100.2/198.6 MB 8.6 MB/s eta 0:00:12\n",
      "   -------------------- ------------------- 100.7/198.6 MB 8.6 MB/s eta 0:00:12\n",
      "   -------------------- ------------------- 101.1/198.6 MB 8.6 MB/s eta 0:00:12\n",
      "   -------------------- ------------------- 101.6/198.6 MB 8.6 MB/s eta 0:00:12\n",
      "   -------------------- ------------------- 102.0/198.6 MB 8.6 MB/s eta 0:00:12\n",
      "   -------------------- ------------------- 102.5/198.6 MB 8.5 MB/s eta 0:00:12\n",
      "   -------------------- ------------------- 103.0/198.6 MB 8.5 MB/s eta 0:00:12\n",
      "   -------------------- ------------------- 103.3/198.6 MB 8.5 MB/s eta 0:00:12\n",
      "   -------------------- ------------------- 103.9/198.6 MB 8.5 MB/s eta 0:00:12\n",
      "   --------------------- ------------------ 104.3/198.6 MB 8.5 MB/s eta 0:00:12\n",
      "   --------------------- ------------------ 104.7/198.6 MB 8.6 MB/s eta 0:00:11\n",
      "   --------------------- ------------------ 105.2/198.6 MB 8.5 MB/s eta 0:00:11\n",
      "   --------------------- ------------------ 105.8/198.6 MB 8.6 MB/s eta 0:00:11\n",
      "   --------------------- ------------------ 106.3/198.6 MB 8.8 MB/s eta 0:00:11\n",
      "   --------------------- ------------------ 106.9/198.6 MB 9.5 MB/s eta 0:00:10\n",
      "   --------------------- ------------------ 107.4/198.6 MB 9.5 MB/s eta 0:00:10\n",
      "   --------------------- ------------------ 107.8/198.6 MB 9.6 MB/s eta 0:00:10\n",
      "   --------------------- ------------------ 108.1/198.6 MB 9.8 MB/s eta 0:00:10\n",
      "   --------------------- ------------------ 108.3/198.6 MB 9.4 MB/s eta 0:00:10\n",
      "   --------------------- ------------------ 108.6/198.6 MB 9.5 MB/s eta 0:00:10\n",
      "   --------------------- ------------------ 109.0/198.6 MB 9.5 MB/s eta 0:00:10\n",
      "   ---------------------- ----------------- 109.4/198.6 MB 9.5 MB/s eta 0:00:10\n",
      "   ---------------------- ----------------- 109.7/198.6 MB 9.2 MB/s eta 0:00:10\n",
      "   ---------------------- ----------------- 109.8/198.6 MB 9.1 MB/s eta 0:00:10\n",
      "   ---------------------- ----------------- 110.4/198.6 MB 9.0 MB/s eta 0:00:10\n",
      "   ---------------------- ----------------- 110.7/198.6 MB 9.1 MB/s eta 0:00:10\n",
      "   ---------------------- ----------------- 111.1/198.6 MB 9.1 MB/s eta 0:00:10\n",
      "   ---------------------- ----------------- 111.6/198.6 MB 9.1 MB/s eta 0:00:10\n",
      "   ---------------------- ----------------- 111.9/198.6 MB 9.0 MB/s eta 0:00:10\n",
      "   ---------------------- ----------------- 112.1/198.6 MB 8.7 MB/s eta 0:00:10\n",
      "   ---------------------- ----------------- 112.4/198.6 MB 8.6 MB/s eta 0:00:11\n",
      "   ---------------------- ----------------- 112.6/198.6 MB 8.5 MB/s eta 0:00:11\n",
      "   ---------------------- ----------------- 112.6/198.6 MB 8.3 MB/s eta 0:00:11\n",
      "   ---------------------- ----------------- 112.8/198.6 MB 8.0 MB/s eta 0:00:11\n",
      "   ---------------------- ----------------- 113.0/198.6 MB 7.8 MB/s eta 0:00:11\n",
      "   ---------------------- ----------------- 113.3/198.6 MB 7.7 MB/s eta 0:00:12\n",
      "   ---------------------- ----------------- 113.5/198.6 MB 7.5 MB/s eta 0:00:12\n",
      "   ---------------------- ----------------- 114.0/198.6 MB 7.5 MB/s eta 0:00:12\n",
      "   ----------------------- ---------------- 114.3/198.6 MB 7.4 MB/s eta 0:00:12\n",
      "   ----------------------- ---------------- 114.5/198.6 MB 7.4 MB/s eta 0:00:12\n",
      "   ----------------------- ---------------- 114.8/198.6 MB 7.2 MB/s eta 0:00:12\n",
      "   ----------------------- ---------------- 115.3/198.6 MB 7.3 MB/s eta 0:00:12\n",
      "   ----------------------- ---------------- 115.7/198.6 MB 7.2 MB/s eta 0:00:12\n",
      "   ----------------------- ---------------- 116.1/198.6 MB 7.1 MB/s eta 0:00:12\n",
      "   ----------------------- ---------------- 116.5/198.6 MB 7.1 MB/s eta 0:00:12\n",
      "   ----------------------- ---------------- 116.7/198.6 MB 7.0 MB/s eta 0:00:12\n",
      "   ----------------------- ---------------- 116.9/198.6 MB 6.8 MB/s eta 0:00:12\n",
      "   ----------------------- ---------------- 117.4/198.6 MB 6.7 MB/s eta 0:00:13\n",
      "   ----------------------- ---------------- 117.7/198.6 MB 6.7 MB/s eta 0:00:13\n",
      "   ----------------------- ---------------- 118.1/198.6 MB 6.7 MB/s eta 0:00:12\n",
      "   ----------------------- ---------------- 118.5/198.6 MB 6.8 MB/s eta 0:00:12\n",
      "   ----------------------- ---------------- 118.7/198.6 MB 6.8 MB/s eta 0:00:12\n",
      "   ------------------------ --------------- 119.2/198.6 MB 6.8 MB/s eta 0:00:12\n",
      "   ------------------------ --------------- 119.5/198.6 MB 6.8 MB/s eta 0:00:12\n",
      "   ------------------------ --------------- 119.7/198.6 MB 6.7 MB/s eta 0:00:12\n",
      "   ------------------------ --------------- 120.0/198.6 MB 6.9 MB/s eta 0:00:12\n",
      "   ------------------------ --------------- 120.4/198.6 MB 6.7 MB/s eta 0:00:12\n",
      "   ------------------------ --------------- 120.9/198.6 MB 6.8 MB/s eta 0:00:12\n",
      "   ------------------------ --------------- 121.1/198.6 MB 6.7 MB/s eta 0:00:12\n",
      "   ------------------------ --------------- 121.4/198.6 MB 6.7 MB/s eta 0:00:12\n",
      "   ------------------------ --------------- 121.5/198.6 MB 6.5 MB/s eta 0:00:12\n",
      "   ------------------------ --------------- 121.8/198.6 MB 6.4 MB/s eta 0:00:12\n",
      "   ------------------------ --------------- 121.9/198.6 MB 6.4 MB/s eta 0:00:13\n",
      "   ------------------------ --------------- 122.1/198.6 MB 6.4 MB/s eta 0:00:13\n",
      "   ------------------------ --------------- 122.3/198.6 MB 6.2 MB/s eta 0:00:13\n",
      "   ------------------------ --------------- 122.6/198.6 MB 6.2 MB/s eta 0:00:13\n",
      "   ------------------------ --------------- 122.9/198.6 MB 6.6 MB/s eta 0:00:12\n",
      "   ------------------------ --------------- 123.1/198.6 MB 6.5 MB/s eta 0:00:12\n",
      "   ------------------------ --------------- 123.4/198.6 MB 6.5 MB/s eta 0:00:12\n",
      "   ------------------------ --------------- 123.9/198.6 MB 6.7 MB/s eta 0:00:12\n",
      "   ------------------------- -------------- 124.4/198.6 MB 6.7 MB/s eta 0:00:11\n",
      "   ------------------------- -------------- 124.9/198.6 MB 7.0 MB/s eta 0:00:11\n",
      "   ------------------------- -------------- 125.4/198.6 MB 7.0 MB/s eta 0:00:11\n",
      "   ------------------------- -------------- 125.9/198.6 MB 7.0 MB/s eta 0:00:11\n",
      "   ------------------------- -------------- 126.3/198.6 MB 7.0 MB/s eta 0:00:11\n",
      "   ------------------------- -------------- 126.6/198.6 MB 7.0 MB/s eta 0:00:11\n",
      "   ------------------------- -------------- 126.9/198.6 MB 7.1 MB/s eta 0:00:11\n",
      "   ------------------------- -------------- 127.2/198.6 MB 7.2 MB/s eta 0:00:10\n",
      "   ------------------------- -------------- 127.5/198.6 MB 7.0 MB/s eta 0:00:11\n",
      "   ------------------------- -------------- 127.9/198.6 MB 7.1 MB/s eta 0:00:10\n",
      "   ------------------------- -------------- 128.2/198.6 MB 7.1 MB/s eta 0:00:10\n",
      "   ------------------------- -------------- 128.6/198.6 MB 7.1 MB/s eta 0:00:10\n",
      "   ------------------------- -------------- 129.0/198.6 MB 7.1 MB/s eta 0:00:10\n",
      "   -------------------------- ------------- 129.5/198.6 MB 7.2 MB/s eta 0:00:10\n",
      "   -------------------------- ------------- 129.8/198.6 MB 7.3 MB/s eta 0:00:10\n",
      "   -------------------------- ------------- 130.2/198.6 MB 7.3 MB/s eta 0:00:10\n",
      "   -------------------------- ------------- 130.6/198.6 MB 7.4 MB/s eta 0:00:10\n",
      "   -------------------------- ------------- 131.1/198.6 MB 7.4 MB/s eta 0:00:10\n",
      "   -------------------------- ------------- 131.5/198.6 MB 7.5 MB/s eta 0:00:09\n",
      "   -------------------------- ------------- 132.0/198.6 MB 7.9 MB/s eta 0:00:09\n",
      "   -------------------------- ------------- 132.3/198.6 MB 8.0 MB/s eta 0:00:09\n",
      "   -------------------------- ------------- 132.7/198.6 MB 8.4 MB/s eta 0:00:08\n",
      "   -------------------------- ------------- 133.1/198.6 MB 8.6 MB/s eta 0:00:08\n",
      "   -------------------------- ------------- 133.5/198.6 MB 8.6 MB/s eta 0:00:08\n",
      "   -------------------------- ------------- 133.9/198.6 MB 8.6 MB/s eta 0:00:08\n",
      "   --------------------------- ------------ 134.4/198.6 MB 8.6 MB/s eta 0:00:08\n",
      "   --------------------------- ------------ 134.8/198.6 MB 8.6 MB/s eta 0:00:08\n",
      "   --------------------------- ------------ 135.3/198.6 MB 8.6 MB/s eta 0:00:08\n",
      "   --------------------------- ------------ 135.8/198.6 MB 8.6 MB/s eta 0:00:08\n",
      "   --------------------------- ------------ 136.3/198.6 MB 8.6 MB/s eta 0:00:08\n",
      "   --------------------------- ------------ 136.7/198.6 MB 8.6 MB/s eta 0:00:08\n",
      "   --------------------------- ------------ 137.1/198.6 MB 8.6 MB/s eta 0:00:08\n",
      "   --------------------------- ------------ 137.6/198.6 MB 9.1 MB/s eta 0:00:07\n",
      "   --------------------------- ------------ 138.1/198.6 MB 9.1 MB/s eta 0:00:07\n",
      "   --------------------------- ------------ 138.5/198.6 MB 9.2 MB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 139.0/198.6 MB 9.4 MB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 139.5/198.6 MB 9.4 MB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 139.9/198.6 MB 9.4 MB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 140.2/198.6 MB 9.2 MB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 140.7/198.6 MB 9.4 MB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 141.1/198.6 MB 9.2 MB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 141.4/198.6 MB 9.4 MB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 142.0/198.6 MB 9.4 MB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 142.4/198.6 MB 9.2 MB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 142.8/198.6 MB 9.5 MB/s eta 0:00:06\n",
      "   ---------------------------- ----------- 143.3/198.6 MB 9.4 MB/s eta 0:00:06\n",
      "   ---------------------------- ----------- 143.7/198.6 MB 9.5 MB/s eta 0:00:06\n",
      "   ---------------------------- ----------- 143.9/198.6 MB 9.5 MB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 144.5/198.6 MB 9.5 MB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 145.0/198.6 MB 9.6 MB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 145.3/198.6 MB 9.4 MB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 145.9/198.6 MB 9.4 MB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 146.4/198.6 MB 9.4 MB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 146.9/198.6 MB 9.5 MB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 147.3/198.6 MB 9.5 MB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 147.6/198.6 MB 9.5 MB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 147.8/198.6 MB 9.1 MB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 148.2/198.6 MB 9.1 MB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 148.6/198.6 MB 9.1 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 149.1/198.6 MB 9.1 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 149.6/198.6 MB 9.1 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 150.0/198.6 MB 9.1 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 150.5/198.6 MB 9.2 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 151.0/198.6 MB 9.2 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 151.4/198.6 MB 9.2 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 151.9/198.6 MB 9.5 MB/s eta 0:00:05\n",
      "   ------------------------------ --------- 152.2/198.6 MB 9.2 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 152.7/198.6 MB 9.2 MB/s eta 0:00:05\n",
      "   ------------------------------ --------- 153.1/198.6 MB 9.4 MB/s eta 0:00:05\n",
      "   ------------------------------ --------- 153.7/198.6 MB 9.4 MB/s eta 0:00:05\n",
      "   ------------------------------- -------- 154.2/198.6 MB 9.5 MB/s eta 0:00:05\n",
      "   ------------------------------- -------- 154.6/198.6 MB 9.5 MB/s eta 0:00:05\n",
      "   ------------------------------- -------- 155.0/198.6 MB 9.5 MB/s eta 0:00:05\n",
      "   ------------------------------- -------- 155.5/198.6 MB 9.5 MB/s eta 0:00:05\n",
      "   ------------------------------- -------- 156.1/198.6 MB 9.5 MB/s eta 0:00:05\n",
      "   ------------------------------- -------- 156.6/198.6 MB 9.6 MB/s eta 0:00:05\n",
      "   ------------------------------- -------- 157.0/198.6 MB 9.5 MB/s eta 0:00:05\n",
      "   ------------------------------- -------- 157.4/198.6 MB 9.5 MB/s eta 0:00:05\n",
      "   ------------------------------- -------- 157.9/198.6 MB 9.9 MB/s eta 0:00:05\n",
      "   ------------------------------- -------- 158.4/198.6 MB 9.9 MB/s eta 0:00:05\n",
      "   ------------------------------- -------- 158.9/198.6 MB 9.9 MB/s eta 0:00:05\n",
      "   ------------------------------- ------- 159.4/198.6 MB 10.1 MB/s eta 0:00:04\n",
      "   ------------------------------- ------- 159.9/198.6 MB 10.1 MB/s eta 0:00:04\n",
      "   ------------------------------- ------- 160.3/198.6 MB 10.2 MB/s eta 0:00:04\n",
      "   -------------------------------- ------- 160.6/198.6 MB 9.8 MB/s eta 0:00:04\n",
      "   -------------------------------- ------- 160.8/198.6 MB 9.6 MB/s eta 0:00:04\n",
      "   -------------------------------- ------- 161.4/198.6 MB 9.6 MB/s eta 0:00:04\n",
      "   -------------------------------- ------- 162.0/198.6 MB 9.9 MB/s eta 0:00:04\n",
      "   ------------------------------- ------- 162.5/198.6 MB 10.1 MB/s eta 0:00:04\n",
      "   -------------------------------- ------- 162.9/198.6 MB 9.9 MB/s eta 0:00:04\n",
      "   -------------------------------- ------- 163.4/198.6 MB 9.9 MB/s eta 0:00:04\n",
      "   -------------------------------- ------- 163.7/198.6 MB 9.8 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 164.2/198.6 MB 9.8 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 164.5/198.6 MB 9.8 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 165.0/198.6 MB 9.6 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 165.4/198.6 MB 9.8 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 165.8/198.6 MB 9.6 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 166.3/198.6 MB 9.5 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 166.7/198.6 MB 9.5 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 167.1/198.6 MB 9.5 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 167.6/198.6 MB 9.5 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 168.1/198.6 MB 9.5 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 168.6/198.6 MB 9.5 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 169.0/198.6 MB 9.6 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 169.3/198.6 MB 9.4 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 169.9/198.6 MB 9.4 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 170.3/198.6 MB 9.4 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 170.8/198.6 MB 9.6 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 171.2/198.6 MB 9.6 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 171.5/198.6 MB 9.6 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 172.0/198.6 MB 9.5 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 172.3/198.6 MB 9.5 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 173.0/198.6 MB 9.5 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 173.4/198.6 MB 9.5 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 173.9/198.6 MB 9.6 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 174.4/198.6 MB 9.6 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 174.8/198.6 MB 9.8 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 175.2/198.6 MB 9.6 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 175.6/198.6 MB 9.5 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 175.9/198.6 MB 9.5 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 176.3/198.6 MB 9.4 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 176.7/198.6 MB 9.4 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 177.1/198.6 MB 9.4 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 177.3/198.6 MB 9.2 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 177.8/198.6 MB 9.1 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 178.0/198.6 MB 9.1 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 178.0/198.6 MB 9.1 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 178.1/198.6 MB 8.3 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 178.1/198.6 MB 8.3 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 178.1/198.6 MB 8.3 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 178.1/198.6 MB 8.3 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 178.4/198.6 MB 7.4 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 178.8/198.6 MB 7.4 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 179.0/198.6 MB 7.2 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 179.3/198.6 MB 7.1 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 179.3/198.6 MB 6.9 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 179.6/198.6 MB 6.8 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 179.7/198.6 MB 6.7 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 180.0/198.6 MB 6.6 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 180.6/198.6 MB 6.7 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 181.2/198.6 MB 6.7 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 181.6/198.6 MB 6.8 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 181.9/198.6 MB 6.8 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 182.4/198.6 MB 6.7 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 183.0/198.6 MB 6.7 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 183.5/198.6 MB 6.7 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 184.1/198.6 MB 6.7 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 184.4/198.6 MB 6.7 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 184.4/198.6 MB 6.7 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 184.4/198.6 MB 6.7 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 184.4/198.6 MB 6.7 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 184.4/198.6 MB 6.7 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 184.4/198.6 MB 6.7 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 184.4/198.6 MB 6.7 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 184.4/198.6 MB 6.7 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 184.5/198.6 MB 5.4 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 184.9/198.6 MB 5.5 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 185.1/198.6 MB 5.4 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 185.5/198.6 MB 5.4 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 185.9/198.6 MB 5.3 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 186.4/198.6 MB 5.5 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 186.8/198.6 MB 5.5 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 187.0/198.6 MB 5.4 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 187.1/198.6 MB 5.3 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 187.3/198.6 MB 5.2 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 187.6/198.6 MB 5.3 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 188.0/198.6 MB 5.2 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 188.4/198.6 MB 6.1 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 188.9/198.6 MB 6.1 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 189.3/198.6 MB 6.2 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 189.7/198.6 MB 6.4 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 190.2/198.6 MB 6.7 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 190.8/198.6 MB 6.7 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 191.3/198.6 MB 6.6 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 191.8/198.6 MB 6.6 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 192.2/198.6 MB 6.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 192.6/198.6 MB 6.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 193.0/198.6 MB 6.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 193.5/198.6 MB 6.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  194.0/198.6 MB 6.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  194.5/198.6 MB 6.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  195.0/198.6 MB 8.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  195.5/198.6 MB 9.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  196.0/198.6 MB 9.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  196.4/198.6 MB 9.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  196.8/198.6 MB 9.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  197.3/198.6 MB 9.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  197.7/198.6 MB 9.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  198.1/198.6 MB 9.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  198.6/198.6 MB 10.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  198.6/198.6 MB 10.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  198.6/198.6 MB 10.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  198.6/198.6 MB 10.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  198.6/198.6 MB 10.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  198.6/198.6 MB 10.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  198.6/198.6 MB 10.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  198.6/198.6 MB 10.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  198.6/198.6 MB 10.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  198.6/198.6 MB 10.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 198.6/198.6 MB 6.2 MB/s eta 0:00:00\n",
      "Downloading typing_extensions-4.10.0-py3-none-any.whl (33 kB)\n",
      "Installing collected packages: typing-extensions, torch\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.7.1\n",
      "    Uninstalling typing_extensions-4.7.1:\n",
      "      Successfully uninstalled typing_extensions-4.7.1\n",
      "Successfully installed torch-2.2.2 typing-extensions-4.10.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc1956c1-36c1-4b35-a384-714c02e1feb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57836760f5ca4ca28825e3d93c0fe5fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mayuo\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\mayuo\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dddf2195be14bc28bd98bc06c2baf49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca26659ebec6439dba5ff32a179b5726",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "30522"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# See how many tokens are in the vocabulary\n",
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3986681-3841-4e27-947e-188b4d1088fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'heart', 'ai']\n",
      "[1045, 2540, 9932]\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer.tokenize(\"I heart AI\")\n",
    "\n",
    "# Print the tokens\n",
    "print(tokens)\n",
    "# ['i', 'heart', 'genera', '##tive', 'ai']\n",
    "\n",
    "# Show the token ids assigned to each token\n",
    "print(tokenizer.convert_tokens_to_ids(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bc7a7ed-1932-42a6-a000-8c1ae3c7d88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mayuo\\anaconda3\\Lib\\site-packages\\transformers\\utils\\generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "from transformers import BertForSequenceClassification, BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d68a05a-0c7d-46c5-8e52-400da5710e37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f9299de0b8c42a680477d4980231160",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/511 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mayuo\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\mayuo\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d93ee1ca63847fbb02051fd031c41d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "BertForSequenceClassification.__init__() got an unexpected keyword argument 'num_lables'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtextattack/bert-base-uncased-imdb\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m BertForSequenceClassification\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name,num_lables \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m      3\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m BertTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\modeling_utils.py:2876\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   2873\u001b[0m     init_contexts\u001b[38;5;241m.\u001b[39mappend(init_empty_weights())\n\u001b[0;32m   2875\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ContextManagers(init_contexts):\n\u001b[1;32m-> 2876\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(config, \u001b[38;5;241m*\u001b[39mmodel_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[0;32m   2878\u001b[0m \u001b[38;5;66;03m# Check first if we are `from_pt`\u001b[39;00m\n\u001b[0;32m   2879\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_keep_in_fp32_modules:\n",
      "\u001b[1;31mTypeError\u001b[0m: BertForSequenceClassification.__init__() got an unexpected keyword argument 'num_lables'"
     ]
    }
   ],
   "source": [
    "model_name = 'textattack/bert-base-uncased-imdb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41a6db7d-9b43-48e2-a6f9-3b9e96cc51ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7426a1330ab49469571326ab2e057d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2cced31613943e180e849cca8707b41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading ()cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "621898f2a2c4426589f24c71edaee152",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87d64d44-17ad-4e89-a83d-c181b39a755d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58f190f9-7e4f-4ba8-88db-790607c6f1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mult_layer_P(nn.Module):\n",
    "    def __init__(self,input_layer):\n",
    "        super(Mult_layer_P,self).__init__()\n",
    "        self.hidden_layer = nn.Linear(input_layer,128)\n",
    "        self.output_layer = nn.Linear(128,10)\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.activation(self.hidden_layer(x))\n",
    "        return self.output_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "851d3c1c-3f6e-479b-a841-0ad97ee41814",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mult_layer_P(\n",
       "  (hidden_layer): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (output_layer): Linear(in_features=128, out_features=10, bias=True)\n",
       "  (activation): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Mult_layer_P(784)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4e299d1-4ffa-480f-aed9-2e0250a64e56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyMLP(\n",
       "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MyMLP(nn.Module):\n",
    "    def __init__(self,input_size):\n",
    "        super(MyMLP,self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size,128)\n",
    "        self.fc2 = nn.Linear(128,10)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim = 1)\n",
    "    def forward(self,x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.softmax(x)\n",
    "\n",
    "        return x\n",
    "my_mlp = MyMLP(784)\n",
    "my_mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402bdc21-40f3-4295-b4be-80aaf0ae3967",
   "metadata": {},
   "outputs": [],
   "source": [
    "## loss functions are in the nn.\n",
    "## optimixer is in torch.optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91095c21-270e-40d8-a23d-10190e03eb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(my_mlp.parameters(), lr = .001) ### you have to have learning rate in it. \n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2542e4cf-3c3f-4f55-89c9-7b230afbac75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, batch 0: 2.29579\n",
      "Epoch 0, batch 1: 2.30623\n",
      "Epoch 0, batch 2: 2.29794\n",
      "Epoch 0, batch 3: 2.29932\n",
      "Epoch 0, batch 4: 2.30344\n",
      "Epoch 0, batch 5: 2.30210\n",
      "Epoch 0, batch 6: 2.30491\n",
      "Epoch 0, batch 7: 2.30574\n",
      "Epoch 0, batch 8: 2.30233\n",
      "Epoch 0, batch 9: 2.30364\n",
      "Epoch 0, batch 10: 2.30122\n",
      "Epoch 0, batch 11: 2.30416\n",
      "Epoch 0, batch 12: 2.30604\n",
      "Epoch 0, batch 13: 2.30462\n",
      "Epoch 0, batch 14: 2.30706\n",
      "Epoch 0, batch 15: 2.30281\n",
      "Epoch 0, batch 16: 2.30690\n",
      "Epoch 0, batch 17: 2.30099\n",
      "Epoch 0, batch 18: 2.30464\n",
      "Epoch 0, batch 19: 2.30269\n",
      "Epoch 0, batch 20: 2.30288\n",
      "Epoch 0, batch 21: 2.30096\n",
      "Epoch 0, batch 22: 2.30188\n",
      "Epoch 0, batch 23: 2.29818\n",
      "Epoch 0, batch 24: 2.30780\n",
      "Epoch 0, batch 25: 2.30740\n",
      "Epoch 0, batch 26: 2.30149\n",
      "Epoch 0, batch 27: 2.29938\n",
      "Epoch 0, batch 28: 2.30191\n",
      "Epoch 0, batch 29: 2.29997\n",
      "Epoch 1, batch 0: 2.30631\n",
      "Epoch 1, batch 1: 2.30022\n",
      "Epoch 1, batch 2: 2.30567\n",
      "Epoch 1, batch 3: 2.29967\n",
      "Epoch 1, batch 4: 2.30588\n",
      "Epoch 1, batch 5: 2.30850\n",
      "Epoch 1, batch 6: 2.30473\n",
      "Epoch 1, batch 7: 2.30352\n",
      "Epoch 1, batch 8: 2.30096\n",
      "Epoch 1, batch 9: 2.30785\n",
      "Epoch 1, batch 10: 2.30177\n",
      "Epoch 1, batch 11: 2.30257\n",
      "Epoch 1, batch 12: 2.30047\n",
      "Epoch 1, batch 13: 2.30668\n",
      "Epoch 1, batch 14: 2.30118\n",
      "Epoch 1, batch 15: 2.30494\n",
      "Epoch 1, batch 16: 2.30398\n",
      "Epoch 1, batch 17: 2.30217\n",
      "Epoch 1, batch 18: 2.30797\n",
      "Epoch 1, batch 19: 2.30233\n",
      "Epoch 1, batch 20: 2.30299\n",
      "Epoch 1, batch 21: 2.30684\n",
      "Epoch 1, batch 22: 2.29894\n",
      "Epoch 1, batch 23: 2.30172\n",
      "Epoch 1, batch 24: 2.30250\n",
      "Epoch 1, batch 25: 2.30226\n",
      "Epoch 1, batch 26: 2.30419\n",
      "Epoch 1, batch 27: 2.30247\n",
      "Epoch 1, batch 28: 2.30219\n",
      "Epoch 1, batch 29: 2.30548\n",
      "Epoch 2, batch 0: 2.30173\n",
      "Epoch 2, batch 1: 2.30511\n",
      "Epoch 2, batch 2: 2.30304\n",
      "Epoch 2, batch 3: 2.29246\n",
      "Epoch 2, batch 4: 2.31110\n",
      "Epoch 2, batch 5: 2.30145\n",
      "Epoch 2, batch 6: 2.30277\n",
      "Epoch 2, batch 7: 2.30358\n",
      "Epoch 2, batch 8: 2.30465\n",
      "Epoch 2, batch 9: 2.30084\n",
      "Epoch 2, batch 10: 2.30474\n",
      "Epoch 2, batch 11: 2.29863\n",
      "Epoch 2, batch 12: 2.29950\n",
      "Epoch 2, batch 13: 2.30598\n",
      "Epoch 2, batch 14: 2.30324\n",
      "Epoch 2, batch 15: 2.30018\n",
      "Epoch 2, batch 16: 2.30941\n",
      "Epoch 2, batch 17: 2.30490\n",
      "Epoch 2, batch 18: 2.30773\n",
      "Epoch 2, batch 19: 2.30075\n",
      "Epoch 2, batch 20: 2.30844\n",
      "Epoch 2, batch 21: 2.30617\n",
      "Epoch 2, batch 22: 2.29999\n",
      "Epoch 2, batch 23: 2.30040\n",
      "Epoch 2, batch 24: 2.30284\n",
      "Epoch 2, batch 25: 2.30618\n",
      "Epoch 2, batch 26: 2.30041\n",
      "Epoch 2, batch 27: 2.30023\n",
      "Epoch 2, batch 28: 2.30478\n",
      "Epoch 2, batch 29: 2.29858\n",
      "Epoch 3, batch 0: 2.30195\n",
      "Epoch 3, batch 1: 2.30638\n",
      "Epoch 3, batch 2: 2.30444\n",
      "Epoch 3, batch 3: 2.30546\n",
      "Epoch 3, batch 4: 2.30310\n",
      "Epoch 3, batch 5: 2.30568\n",
      "Epoch 3, batch 6: 2.30096\n",
      "Epoch 3, batch 7: 2.29936\n",
      "Epoch 3, batch 8: 2.30490\n",
      "Epoch 3, batch 9: 2.30316\n",
      "Epoch 3, batch 10: 2.30260\n",
      "Epoch 3, batch 11: 2.29971\n",
      "Epoch 3, batch 12: 2.30280\n",
      "Epoch 3, batch 13: 2.30518\n",
      "Epoch 3, batch 14: 2.30359\n",
      "Epoch 3, batch 15: 2.29800\n",
      "Epoch 3, batch 16: 2.30257\n",
      "Epoch 3, batch 17: 2.30287\n",
      "Epoch 3, batch 18: 2.30145\n",
      "Epoch 3, batch 19: 2.30270\n",
      "Epoch 3, batch 20: 2.30137\n",
      "Epoch 3, batch 21: 2.30389\n",
      "Epoch 3, batch 22: 2.30351\n",
      "Epoch 3, batch 23: 2.30393\n",
      "Epoch 3, batch 24: 2.30270\n",
      "Epoch 3, batch 25: 2.30445\n",
      "Epoch 3, batch 26: 2.30119\n",
      "Epoch 3, batch 27: 2.30679\n",
      "Epoch 3, batch 28: 2.30694\n",
      "Epoch 3, batch 29: 2.30297\n",
      "Epoch 4, batch 0: 2.30120\n",
      "Epoch 4, batch 1: 2.30635\n",
      "Epoch 4, batch 2: 2.30291\n",
      "Epoch 4, batch 3: 2.30228\n",
      "Epoch 4, batch 4: 2.30178\n",
      "Epoch 4, batch 5: 2.30413\n",
      "Epoch 4, batch 6: 2.30540\n",
      "Epoch 4, batch 7: 2.30244\n",
      "Epoch 4, batch 8: 2.30349\n",
      "Epoch 4, batch 9: 2.30558\n",
      "Epoch 4, batch 10: 2.30233\n",
      "Epoch 4, batch 11: 2.30635\n",
      "Epoch 4, batch 12: 2.29864\n",
      "Epoch 4, batch 13: 2.30287\n",
      "Epoch 4, batch 14: 2.30282\n",
      "Epoch 4, batch 15: 2.30004\n",
      "Epoch 4, batch 16: 2.30196\n",
      "Epoch 4, batch 17: 2.30446\n",
      "Epoch 4, batch 18: 2.29939\n",
      "Epoch 4, batch 19: 2.30259\n",
      "Epoch 4, batch 20: 2.30309\n",
      "Epoch 4, batch 21: 2.30222\n",
      "Epoch 4, batch 22: 2.30336\n",
      "Epoch 4, batch 23: 2.30401\n",
      "Epoch 4, batch 24: 2.30611\n",
      "Epoch 4, batch 25: 2.29885\n",
      "Epoch 4, batch 26: 2.30358\n",
      "Epoch 4, batch 27: 2.29961\n",
      "Epoch 4, batch 28: 2.30261\n",
      "Epoch 4, batch 29: 2.30050\n",
      "Epoch 5, batch 0: 2.29959\n",
      "Epoch 5, batch 1: 2.30310\n",
      "Epoch 5, batch 2: 2.30454\n",
      "Epoch 5, batch 3: 2.30184\n",
      "Epoch 5, batch 4: 2.30502\n",
      "Epoch 5, batch 5: 2.30590\n",
      "Epoch 5, batch 6: 2.30242\n",
      "Epoch 5, batch 7: 2.29904\n",
      "Epoch 5, batch 8: 2.30595\n",
      "Epoch 5, batch 9: 2.31021\n",
      "Epoch 5, batch 10: 2.30215\n",
      "Epoch 5, batch 11: 2.30535\n",
      "Epoch 5, batch 12: 2.30251\n",
      "Epoch 5, batch 13: 2.30149\n",
      "Epoch 5, batch 14: 2.30508\n",
      "Epoch 5, batch 15: 2.30775\n",
      "Epoch 5, batch 16: 2.30565\n",
      "Epoch 5, batch 17: 2.30828\n",
      "Epoch 5, batch 18: 2.30502\n",
      "Epoch 5, batch 19: 2.30222\n",
      "Epoch 5, batch 20: 2.30346\n",
      "Epoch 5, batch 21: 2.29975\n",
      "Epoch 5, batch 22: 2.30434\n",
      "Epoch 5, batch 23: 2.30455\n",
      "Epoch 5, batch 24: 2.30350\n",
      "Epoch 5, batch 25: 2.30312\n",
      "Epoch 5, batch 26: 2.29900\n",
      "Epoch 5, batch 27: 2.30439\n",
      "Epoch 5, batch 28: 2.30330\n",
      "Epoch 5, batch 29: 2.30722\n",
      "Epoch 6, batch 0: 2.29922\n",
      "Epoch 6, batch 1: 2.31305\n",
      "Epoch 6, batch 2: 2.29894\n",
      "Epoch 6, batch 3: 2.30437\n",
      "Epoch 6, batch 4: 2.30389\n",
      "Epoch 6, batch 5: 2.29943\n",
      "Epoch 6, batch 6: 2.30312\n",
      "Epoch 6, batch 7: 2.29895\n",
      "Epoch 6, batch 8: 2.30283\n",
      "Epoch 6, batch 9: 2.29834\n",
      "Epoch 6, batch 10: 2.30056\n",
      "Epoch 6, batch 11: 2.30496\n",
      "Epoch 6, batch 12: 2.30379\n",
      "Epoch 6, batch 13: 2.30462\n",
      "Epoch 6, batch 14: 2.30947\n",
      "Epoch 6, batch 15: 2.30565\n",
      "Epoch 6, batch 16: 2.29981\n",
      "Epoch 6, batch 17: 2.30061\n",
      "Epoch 6, batch 18: 2.30416\n",
      "Epoch 6, batch 19: 2.30328\n",
      "Epoch 6, batch 20: 2.30332\n",
      "Epoch 6, batch 21: 2.30190\n",
      "Epoch 6, batch 22: 2.30044\n",
      "Epoch 6, batch 23: 2.30475\n",
      "Epoch 6, batch 24: 2.30325\n",
      "Epoch 6, batch 25: 2.29770\n",
      "Epoch 6, batch 26: 2.29858\n",
      "Epoch 6, batch 27: 2.30052\n",
      "Epoch 6, batch 28: 2.30538\n",
      "Epoch 6, batch 29: 2.30346\n",
      "Epoch 7, batch 0: 2.30394\n",
      "Epoch 7, batch 1: 2.29867\n",
      "Epoch 7, batch 2: 2.30129\n",
      "Epoch 7, batch 3: 2.30873\n",
      "Epoch 7, batch 4: 2.30191\n",
      "Epoch 7, batch 5: 2.30727\n",
      "Epoch 7, batch 6: 2.30419\n",
      "Epoch 7, batch 7: 2.31011\n",
      "Epoch 7, batch 8: 2.30675\n",
      "Epoch 7, batch 9: 2.30399\n",
      "Epoch 7, batch 10: 2.30391\n",
      "Epoch 7, batch 11: 2.30332\n",
      "Epoch 7, batch 12: 2.30000\n",
      "Epoch 7, batch 13: 2.30549\n",
      "Epoch 7, batch 14: 2.30364\n",
      "Epoch 7, batch 15: 2.30645\n",
      "Epoch 7, batch 16: 2.30722\n",
      "Epoch 7, batch 17: 2.30604\n",
      "Epoch 7, batch 18: 2.29849\n",
      "Epoch 7, batch 19: 2.30720\n",
      "Epoch 7, batch 20: 2.30039\n",
      "Epoch 7, batch 21: 2.30275\n",
      "Epoch 7, batch 22: 2.30670\n",
      "Epoch 7, batch 23: 2.29995\n",
      "Epoch 7, batch 24: 2.30549\n",
      "Epoch 7, batch 25: 2.30081\n",
      "Epoch 7, batch 26: 2.29985\n",
      "Epoch 7, batch 27: 2.30146\n",
      "Epoch 7, batch 28: 2.30137\n",
      "Epoch 7, batch 29: 2.30435\n",
      "Epoch 8, batch 0: 2.30158\n",
      "Epoch 8, batch 1: 2.30420\n",
      "Epoch 8, batch 2: 2.29766\n",
      "Epoch 8, batch 3: 2.30311\n",
      "Epoch 8, batch 4: 2.29976\n",
      "Epoch 8, batch 5: 2.30479\n",
      "Epoch 8, batch 6: 2.30198\n",
      "Epoch 8, batch 7: 2.30198\n",
      "Epoch 8, batch 8: 2.30861\n",
      "Epoch 8, batch 9: 2.29798\n",
      "Epoch 8, batch 10: 2.29885\n",
      "Epoch 8, batch 11: 2.30260\n",
      "Epoch 8, batch 12: 2.30229\n",
      "Epoch 8, batch 13: 2.30666\n",
      "Epoch 8, batch 14: 2.30118\n",
      "Epoch 8, batch 15: 2.30690\n",
      "Epoch 8, batch 16: 2.29880\n",
      "Epoch 8, batch 17: 2.30438\n",
      "Epoch 8, batch 18: 2.30423\n",
      "Epoch 8, batch 19: 2.29918\n",
      "Epoch 8, batch 20: 2.30181\n",
      "Epoch 8, batch 21: 2.30276\n",
      "Epoch 8, batch 22: 2.29874\n",
      "Epoch 8, batch 23: 2.30007\n",
      "Epoch 8, batch 24: 2.30382\n",
      "Epoch 8, batch 25: 2.29798\n",
      "Epoch 8, batch 26: 2.30578\n",
      "Epoch 8, batch 27: 2.30271\n",
      "Epoch 8, batch 28: 2.30262\n",
      "Epoch 8, batch 29: 2.30431\n",
      "Epoch 9, batch 0: 2.30558\n",
      "Epoch 9, batch 1: 2.29997\n",
      "Epoch 9, batch 2: 2.30292\n",
      "Epoch 9, batch 3: 2.29954\n",
      "Epoch 9, batch 4: 2.30124\n",
      "Epoch 9, batch 5: 2.30345\n",
      "Epoch 9, batch 6: 2.30016\n",
      "Epoch 9, batch 7: 2.29996\n",
      "Epoch 9, batch 8: 2.30670\n",
      "Epoch 9, batch 9: 2.30260\n",
      "Epoch 9, batch 10: 2.30218\n",
      "Epoch 9, batch 11: 2.30265\n",
      "Epoch 9, batch 12: 2.29956\n",
      "Epoch 9, batch 13: 2.30532\n",
      "Epoch 9, batch 14: 2.30473\n",
      "Epoch 9, batch 15: 2.30289\n",
      "Epoch 9, batch 16: 2.30241\n",
      "Epoch 9, batch 17: 2.30388\n",
      "Epoch 9, batch 18: 2.30039\n",
      "Epoch 9, batch 19: 2.30626\n",
      "Epoch 9, batch 20: 2.29897\n",
      "Epoch 9, batch 21: 2.29823\n",
      "Epoch 9, batch 22: 2.30237\n",
      "Epoch 9, batch 23: 2.30313\n",
      "Epoch 9, batch 24: 2.29607\n",
      "Epoch 9, batch 25: 2.30456\n",
      "Epoch 9, batch 26: 2.30178\n",
      "Epoch 9, batch 27: 2.30254\n",
      "Epoch 9, batch 28: 2.29860\n",
      "Epoch 9, batch 29: 2.29716\n"
     ]
    }
   ],
   "source": [
    "def fake_training_loaders():\n",
    "    for _ in range(30):\n",
    "        yield torch.randn(64,784), torch.randint(0,10,(64,))\n",
    "\n",
    "for epochs in range(10):\n",
    "    for i,data in enumerate(fake_training_loaders()):\n",
    "        x,y = data\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = my_mlp.forward(x)\n",
    "        loss = loss_fn(y_pred,y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        print(f\"Epoch {epochs}, batch {i}: {loss.item():.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab0adad-e029-47f8-9d53-c519f393eb15",
   "metadata": {},
   "source": [
    "#### Hugging face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "842b8c05-e4a5-44d9-9c6f-73558ecbcd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace <MASK> with the appropriate code to complete the exercise.\n",
    "\n",
    "# Get the model and tokenizer\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "pt_model = AutoModelForSequenceClassification.from_pretrained('distilbert-base-uncased-finetuned-sst-2-english')\n",
    "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased-finetuned-sst-2-english')\n",
    "\n",
    "\n",
    "def get_prediction(review):\n",
    "    \"\"\"Given a review, return the predicted sentiment\"\"\"\n",
    "\n",
    "    # Tokenize the review\n",
    "    # (Get the response as tensors and not as a list)\n",
    "    inputs = tokenizer(review, return_tensors='pt')\n",
    "\n",
    "    # Perform the prediction (get the logits)\n",
    "    outputs = pt_model(**inputs)\n",
    "\n",
    "    # Get the predicted class (corresponding to the highest logit)\n",
    "    predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "\n",
    "    return \"positive\" if predictions.item() == 1 else \"negative\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f0ed3abe-55ba-47a5-9f13-f31bafc087e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_prediction('this movie is great')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "be4e9d58-edde-40cb-a857-bf997926a5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "627ac7b9-14e8-409d-a202-d064078e7cfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0a60c3da324427eaec28cab79dacef3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/7.62k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset None/plain_text to C:/Users/mayuo/.cache/huggingface/datasets/parquet/plain_text-57edf78d6033ac9a/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0efe3c0203d4a04b4468a680a3dabde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c428cfeca9f4ead9f8774bddc4617de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/14.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26b8f396e55a4c95b7e72356de131d2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/1.82M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b9cc9a99cab499f80437c44f8ae712f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/87599 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/10570 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset parquet downloaded and prepared to C:/Users/mayuo/.cache/huggingface/datasets/parquet/plain_text-57edf78d6033ac9a/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de273dd6310546b8ac579f5e23e8139e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 87599\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 10570\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset('squad')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58aafca-ce34-4e88-bd48-c26262aa9b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_v1 = load_dataset('imdb', split= ['train'])\n",
    "dt_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e55593bb-3d21-45ed-8e63-5d2be8a68771",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31fe40ee-13bd-4cb8-b4d3-2def5fa60699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d021aee9b7d4df3afd184a8bde04366",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/3.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df9d97a1db1a40c891751af71dfeb589",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/4.87k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset sms_spam/plain_text to C:/Users/mayuo/.cache/huggingface/datasets/sms_spam/plain_text/1.0.0/53f051d3b5f62d99d61792c91acefe4f1577ad3e4c216fb0ad39e30b9f20019c...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5163d87835df4364bf738dc185a32640",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/5574 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset sms_spam downloaded and prepared to C:/Users/mayuo/.cache/huggingface/datasets/sms_spam/plain_text/1.0.0/53f051d3b5f62d99d61792c91acefe4f1577ad3e4c216fb0ad39e30b9f20019c. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93c478d6da4b4c09a964d90ac47b78b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['sms', 'label'],\n",
       "    num_rows: 5574\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset('sms_spam',split = ['train'])[0]\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1782511-3715-485d-9ca3-2b0e44b354af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label = 0, sms = Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\n",
      "\n",
      "label = 0, sms = Ok lar... Joking wif u oni...\n",
      "\n",
      "label = 1, sms = Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for entry in dataset.select(range(3)):\n",
    "    sms = entry['sms']\n",
    "    label = entry['label']\n",
    "    print(f'label = {label}, sms = {sms}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85b3e0da-3902-42e3-bd39-f5bb99f59d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### making dict to help us understand labels better\n",
    "id2label = {0 : 'Not Spam',\n",
    "            1 : 'Spam'}\n",
    "label2id = {'Not Spam': 0,\n",
    "            'Spam': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eba49844-1eb2-4ef7-aba8-c0489d1df0d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label = Not Spam\n",
      "sms = Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\n",
      "\n",
      "label = Not Spam\n",
      "sms = Ok lar... Joking wif u oni...\n",
      "\n",
      "label = Spam\n",
      "sms = Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\n",
      "\n",
      "label = Not Spam\n",
      "sms = U dun say so early hor... U c already then say...\n",
      "\n",
      "label = Not Spam\n",
      "sms = Nah I don't think he goes to usf, he lives around here though\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for entry in dataset.select(range(5)):\n",
    "    sms = entry['sms']\n",
    "    id_label = entry['label']\n",
    "    print(f'label = {id2label[id_label]}\\nsms = {sms}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d67f73c-5fe6-401e-98ed-f615ce5cf5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sms_messages_string(dataset, range_of_items, include_label = False):\n",
    "    for num,data in zip(range_of_items,dataset.select(range_of_items)):\n",
    "        sms = data['sms']\n",
    "        id_label = data['label']\n",
    "\n",
    "        if include_label:\n",
    "            \n",
    "            print(f'label = {id2label[id_label]}\\nsms = {sms}')\n",
    "        else:\n",
    "            print(f'The sms is {sms}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42edc8a8-db62-4288-aa92-08ad2a5b4fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label = Not Spam\n",
      "sms = Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\n",
      "\n",
      "label = Not Spam\n",
      "sms = Ok lar... Joking wif u oni...\n",
      "\n",
      "label = Spam\n",
      "sms = Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_sms_messages_string(dataset, range(3), include_label=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b08e04-c456-458d-8aae-443a752a539c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5e9ce2-632f-4a73-9090-27492c05002a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0971883-4ee1-45bc-8200-bff7dae2bf74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82b37c9-cbc4-4c81-87ba-a007cc6b8e90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c811761-3a5a-4a0c-96b9-9dea46f3b7be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa59588-6318-487e-962d-bae7f241db9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e411e6-d690-4595-8def-123627c44469",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52028eee-35de-4385-84a2-d6801c4181b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4268b242-b65c-4b91-a966-618691d60aee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27d9f06-72a5-4089-a8e9-62ed22b7c767",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2f8fba-e039-4a1a-82d3-2609e097d609",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f34f07a-eb53-4a3c-a2eb-347877772bfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dab36aa-ae10-457d-94a3-51e83139a145",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2c51a6-b37d-496b-b522-24aee3cac9b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31a2c9f-7ec7-4b6b-bfdd-a81a51664a85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d716faaa-f381-43a5-ad54-b8630f3d270c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94f067c-ef39-40a1-9fae-ca747797a712",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5abac63-0f56-4d5e-985d-537831236862",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3874f624-5038-4780-9782-2a577ceed964",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b9eea0-101a-4f03-8cf7-e300b46d6819",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f56483-45b4-4862-b864-1787a2560a4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1227279-a765-4932-b66f-251b9ec0ee3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ebef7e-6fd7-4d24-9195-7611124e9f07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de1ff58-6445-4906-8294-cbe55151f1b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a909d888-fcc6-4114-9d69-7430c2213953",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06304ea-0dc2-4ede-a734-9ad4d592e953",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05004570-c3d7-4d18-baf7-52c7b4a25658",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d0f4dc-38d0-464f-9b5f-ae174c37a93e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d27b4b3-4956-480b-a682-37f1d12dd5dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0db5620-65d7-4e2a-8de3-9db4862bb104",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec08a38f-ef2f-4769-aec5-a56774903117",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef42fba-151e-4274-bc93-210164188985",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d80b8c-c42a-4846-8125-113fc58be91c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785074bc-037f-40b5-8938-7b53ad3b01e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de24530b-04b7-4373-a173-761e448b5ebf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cb0e44-c8b3-471d-bd3d-a734c769177d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ef898b-edc6-47c7-8b59-ca6706aa2b57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b35c864-d6de-46c3-94b5-6fd4f6e2e616",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3e9fa0-a6a1-4b95-9782-8cf154d587bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c58d2c-5f9d-4688-9d39-fc807576736b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c8ff39-3e74-46a4-b2ef-422882c7206f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbbaacc-f70f-49f4-8f01-a0cb124ff26f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9075acd7-7ac9-415c-b00e-62e7e3b5c2f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef323d1-8672-4f19-8f21-f33cdc49076f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc6b1e1-051b-4f23-aa60-d2b18a5529b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b17803b-1e8d-472c-908b-86375af86fa0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b5906a-e550-4037-9671-64d2b697dd36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
