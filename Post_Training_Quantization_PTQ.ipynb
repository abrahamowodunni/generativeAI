{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c31a0091-b305-49a2-b09b-4585eb9c117f",
   "metadata": {},
   "source": [
    "### What Post Traing Quantization is..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03765447-ebfd-4cca-8c89-9845c050956c",
   "metadata": {},
   "source": [
    "#### Importing the required libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22bd3957-99b2-4d3c-9018-f977efce8e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b24e11-4154-4b15-9ebe-cd5e5928ddda",
   "metadata": {},
   "source": [
    "#### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d35a060f-c80d-4896-9a0c-4c1bc47e5c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = torch.manual_seed(433)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9621d56f-e932-409f-853d-cbd958fc7322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 9912422/9912422 [00:01<00:00, 5556356.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 28881/28881 [00:00<00:00, 400398.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 1648877/1648877 [00:00<00:00, 3320136.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 4542/4542 [00:00<00:00, 4554274.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(), # converting to tensors\n",
    "    transforms.Normalize((0.1307,), (0.3081,)) # performing normalization on the data which is optimal in ML or DL\n",
    "])\n",
    "\n",
    "# we would be using the MNIST dataset\n",
    "mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "mnist_testset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# creating batch norm\n",
    "train_loader = torch.utils.data.DataLoader(mnist_trainset, batch_size=10, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(mnist_testset, batch_size=10, shuffle=True)\n",
    "\n",
    "# trying to leverage my baby GPU hahahaha ;)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88781bb7-b846-43cc-9c89-e9ec7ddc6c85",
   "metadata": {},
   "source": [
    "#### Simple Neural Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e986788-c7e3-4687-8747-10a71a40d6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, hidden_layer_1 = 50,hidden_layer_2 = 80, hidden_layer_3 = 30):\n",
    "        super(NeuralNetwork,self).__init__()\n",
    "        self.linear1 = nn.Linear(28*28, hidden_layer_1)\n",
    "        self.linear2 = nn.Linear(hidden_layer_1, hidden_layer_2)\n",
    "        self.linear3 = nn.Linear(hidden_layer_2, hidden_layer_3)\n",
    "        self.linear4 = nn.Linear(hidden_layer_3, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self,img):\n",
    "        x = img.view(-1, 28*28)\n",
    "        x = self.relu(self.linear1(x))\n",
    "        x = self.relu(self.linear2(x))\n",
    "        x = self.relu(self.linear3(x))\n",
    "        x = self.linear4(x)\n",
    "        return x\n",
    "\n",
    "model = NeuralNetwork().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbea275-b5eb-4029-8293-c8b33681a1f1",
   "metadata": {},
   "source": [
    "#### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16e147cd-0de2-4375-9686-8d22aefee94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, epochs = None, total_iterations_limit = None):\n",
    "    # optimizer and loss function\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    loss_function = nn.CrossEntropyLoss() # since this is a classification problem.\n",
    "\n",
    "    total_iterations = 0  # Keep track of how many total iterations we've done\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "\n",
    "        loss_sum = 0  # Sum of all the losses to calculate the average loss\n",
    "        num_iterations = 0  # Keep track of the iterations in this epoch\n",
    "        data_iterator = tqdm(train_loader, desc=f'Epoch {epoch+1}')\n",
    "\n",
    "        if total_iterations_limit is not None:\n",
    "            data_iterator.total = total_iterations_limit\n",
    "        for data in data_iterator:\n",
    "            num_iterations += 1\n",
    "            total_iterations += 1\n",
    "            x, y = data # 'data' is a batch (x, y), where x is the input (image), and y is the label (digit)\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(x.view(-1, 28*28))\n",
    "            loss = loss_function(output, y)\n",
    "            loss_sum += loss.item()\n",
    "            avg_loss = loss_sum / num_iterations\n",
    "            data_iterator.set_postfix(loss=avg_loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # If a total iteration limit is set, stop training once the limit is reached\n",
    "            if total_iterations_limit is not None and total_iterations >= total_iterations_limit:\n",
    "                return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cda83a0-b002-4f51-b6b6-424cc08611a8",
   "metadata": {},
   "source": [
    "#### Function to print the size of the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c46c5b0f-bf32-49df-8ebe-40941a6907d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|████████████████████████████████████████████████████████| 6000/6000 [00:58<00:00, 101.70it/s, loss=0.135]\n"
     ]
    }
   ],
   "source": [
    "def print_size_of_model(model):\n",
    "    torch.save(model.state_dict(), \"temp_delme.p\")\n",
    "    print('Size (KB):', os.path.getsize(\"temp_delme.p\")/1e3)\n",
    "    os.remove('temp_delme.p')\n",
    "\n",
    "MODEL_FILENAME = 'simpleNN_ptq.pt'\n",
    "\n",
    "if Path(MODEL_FILENAME).exists():\n",
    "    model.load_state_dict(torch.load(MODEL_FILENAME))\n",
    "    print('Loaded model from disk')\n",
    "else:\n",
    "    train(train_loader, model, epochs=1)\n",
    "    # Save the model to disk\n",
    "    torch.save(model.state_dict(), MODEL_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51099455-0543-446e-84f5-5a324d73a43b",
   "metadata": {},
   "source": [
    "#### Time to test our Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b01a44a8-4cd1-4bdc-9fec-cdedc75d6f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, total_iterations):\n",
    "    correct,total, iterations = 0,0,0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(test_loader, desc='Testing'):\n",
    "            x, y = data\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            output = model(x.view(-1, 784))\n",
    "            for idx, i in enumerate(output):\n",
    "                if torch.argmax(i) == y[idx]:\n",
    "                    correct +=1\n",
    "                total +=1\n",
    "            iterations += 1\n",
    "            if total_iterations is not None and iterations >= total_iterations:\n",
    "                break\n",
    "    print(f'Accuracy: {round(correct/total, 8)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27c7c3a-2687-4574-aa8b-c2e06939f5c3",
   "metadata": {},
   "source": [
    "#### Looking at the values of the tensors and the size of model before quatization !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5a0b8c9-af3b-4dde-b100-13217698e792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights before quantization\n",
      "Parameter containing:\n",
      "tensor([[ 2.2669e-02,  2.1956e-02, -2.6446e-03,  ...,  3.9206e-03,\n",
      "          3.7860e-02,  4.6699e-03],\n",
      "        [ 9.6753e-05,  3.8221e-02,  1.9658e-02,  ..., -6.3200e-03,\n",
      "          2.2407e-02, -1.6425e-02],\n",
      "        [ 5.9448e-02,  4.3217e-03,  1.6101e-02,  ..., -7.5925e-03,\n",
      "          7.5968e-03,  2.9488e-02],\n",
      "        ...,\n",
      "        [-1.2917e-02,  1.4802e-02,  6.9440e-03,  ...,  3.6022e-04,\n",
      "         -9.9758e-03,  9.7989e-03],\n",
      "        [-3.5000e-03,  4.5107e-02,  1.5952e-02,  ...,  3.1508e-02,\n",
      "          2.7726e-02,  3.5913e-02],\n",
      "        [-3.3904e-02,  1.7777e-02, -3.4840e-03,  ...,  2.9134e-03,\n",
      "         -1.7864e-03,  1.2128e-02]], requires_grad=True)\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "# Print the weights matrix of the model before quantization\n",
    "print('Weights before quantization')\n",
    "print(model.linear1.weight) # for the 1st layer. \n",
    "print(model.linear1.weight.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "381ce708-10e4-41c2-a1c3-e1594c0e5ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the model before quantization\n",
      "Size (KB): 187.364\n"
     ]
    }
   ],
   "source": [
    "print('Size of the model before quantization')\n",
    "print_size_of_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be51f0ef-641a-4f3d-a929-a06b28b190e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model before quantization: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|████████████████████████████████████████████████████████████████████| 1000/1000 [00:03<00:00, 291.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## we also want to check the accuracy of our model \n",
    "print(f'Accuracy of the model before quantization: ')\n",
    "test(model,None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c6245a-6e36-4960-b4db-8fe39f439c4d",
   "metadata": {},
   "source": [
    "### Time to Quantize ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15f05c55-1114-426c-9763-fc0f9a0f9ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### We make a copy of that same model: \n",
    "class QuantizeNeuralNetwork(nn.Module):\n",
    "    def __init__(self, hidden_layer_1 = 50,hidden_layer_2 = 80, hidden_layer_3 = 30):\n",
    "        super(QuantizeNeuralNetwork,self).__init__()\n",
    "        self.quant = torch.quantization.QuantStub()\n",
    "        self.linear1 = nn.Linear(28*28, hidden_layer_1)\n",
    "        self.linear2 = nn.Linear(hidden_layer_1, hidden_layer_2)\n",
    "        self.linear3 = nn.Linear(hidden_layer_2, hidden_layer_3)\n",
    "        self.linear4 = nn.Linear(hidden_layer_3, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dequant = torch.quantization.DeQuantStub()\n",
    "        \n",
    "    def forward(self,img):\n",
    "        x = img.view(-1, 28*28)\n",
    "        x = self.quant(x)\n",
    "        x = self.relu(self.linear1(x))\n",
    "        x = self.relu(self.linear2(x))\n",
    "        x = self.relu(self.linear3(x))\n",
    "        x = self.linear4(x)\n",
    "        x = self.dequant(x)\n",
    "        return x\n",
    "\n",
    "quant_model = QuantizeNeuralNetwork().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f528346e-24b1-4eaf-966a-db0b13ec7a15",
   "metadata": {},
   "source": [
    "#### So i am not going to retrain but just copy the weights and get inference for the quantized version... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b2ea4ec-473d-4c95-b654-7d6b34e96fbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QuantizeNeuralNetwork(\n",
       "  (quant): QuantStub(\n",
       "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  )\n",
       "  (linear1): Linear(\n",
       "    in_features=784, out_features=50, bias=True\n",
       "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  )\n",
       "  (linear2): Linear(\n",
       "    in_features=50, out_features=80, bias=True\n",
       "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  )\n",
       "  (linear3): Linear(\n",
       "    in_features=80, out_features=30, bias=True\n",
       "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  )\n",
       "  (linear4): Linear(\n",
       "    in_features=30, out_features=10, bias=True\n",
       "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  )\n",
       "  (relu): ReLU()\n",
       "  (dequant): DeQuantStub()\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quant_model.load_state_dict(model.state_dict())\n",
    "quant_model.eval() ## we are not training but foing inferencing \n",
    "\n",
    "quant_model.qconfig = torch.ao.quantization.default_qconfig\n",
    "quant_model = torch.ao.quantization.prepare(quant_model) # Insert observers\n",
    "quant_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d12b14fb-e9a7-470d-ba4f-e40e81a35faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|████████████████████████████████████████████████████████████████████| 1000/1000 [00:02<00:00, 385.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9646\n",
      "Check statistics of the various layers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "QuantizeNeuralNetwork(\n",
       "  (quant): QuantStub(\n",
       "    (activation_post_process): MinMaxObserver(min_val=-0.4242129623889923, max_val=2.821486711502075)\n",
       "  )\n",
       "  (linear1): Linear(\n",
       "    in_features=784, out_features=50, bias=True\n",
       "    (activation_post_process): MinMaxObserver(min_val=-58.53604507446289, max_val=43.8294563293457)\n",
       "  )\n",
       "  (linear2): Linear(\n",
       "    in_features=50, out_features=80, bias=True\n",
       "    (activation_post_process): MinMaxObserver(min_val=-40.140647888183594, max_val=35.24177551269531)\n",
       "  )\n",
       "  (linear3): Linear(\n",
       "    in_features=80, out_features=30, bias=True\n",
       "    (activation_post_process): MinMaxObserver(min_val=-36.355369567871094, max_val=43.074493408203125)\n",
       "  )\n",
       "  (linear4): Linear(\n",
       "    in_features=30, out_features=10, bias=True\n",
       "    (activation_post_process): MinMaxObserver(min_val=-36.072540283203125, max_val=22.88129234313965)\n",
       "  )\n",
       "  (relu): ReLU()\n",
       "  (dequant): DeQuantStub()\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(quant_model,None)\n",
    "print(f'Check statistics of the various layers')\n",
    "quant_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0df630-425a-4ae9-aafc-e1c15ef84ef0",
   "metadata": {},
   "source": [
    "I think this is beautiful as we can see this values of this tensors. It gives us an Idea for how to go about each layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fdd85e8-30fe-4540-a2f0-ddf70ebe69e1",
   "metadata": {},
   "source": [
    "### Quantization using the statistics gathered from the observer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "29ff3da3-c6c6-46b9-9153-e923ffb4c34e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check statistics of the various layers\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "QuantizeNeuralNetwork(\n",
       "  (quant): Quantize(scale=tensor([0.0256]), zero_point=tensor([17]), dtype=torch.quint8)\n",
       "  (linear1): QuantizedLinear(in_features=784, out_features=50, scale=0.8060275912284851, zero_point=73, qscheme=torch.per_tensor_affine)\n",
       "  (linear2): QuantizedLinear(in_features=50, out_features=80, scale=0.5935623645782471, zero_point=68, qscheme=torch.per_tensor_affine)\n",
       "  (linear3): QuantizedLinear(in_features=80, out_features=30, scale=0.625432014465332, zero_point=58, qscheme=torch.per_tensor_affine)\n",
       "  (linear4): QuantizedLinear(in_features=30, out_features=10, scale=0.464203417301178, zero_point=78, qscheme=torch.per_tensor_affine)\n",
       "  (relu): ReLU()\n",
       "  (dequant): DeQuantize()\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quant_model = torch.ao.quantization.convert(quant_model)\n",
    "print(f'Check statistics of the various layers')\n",
    "quant_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4650b39-fd99-4b00-8903-16235684981b",
   "metadata": {},
   "source": [
    "So for each layer it has it's own Scale and zero point. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "331e2954-09f2-4abe-afdc-8f1042aba7a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights after quantization\n",
      "tensor([[ 4,  4,  0,  ...,  1,  6,  1],\n",
      "        [ 0,  6,  3,  ..., -1,  4, -3],\n",
      "        [10,  1,  3,  ..., -1,  1,  5],\n",
      "        ...,\n",
      "        [-2,  2,  1,  ...,  0, -2,  2],\n",
      "        [-1,  7,  3,  ...,  5,  5,  6],\n",
      "        [-6,  3, -1,  ...,  0,  0,  2]], dtype=torch.int8)\n"
     ]
    }
   ],
   "source": [
    "# Print the weights matrix of the model after quantization\n",
    "print('Weights after quantization')\n",
    "print(torch.int_repr(quant_model.linear1.weight()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "babcd50e-55c5-40b5-97be-b557ba7f8a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original weights: \n",
      "Parameter containing:\n",
      "tensor([[ 2.2669e-02,  2.1956e-02, -2.6446e-03,  ...,  3.9206e-03,\n",
      "          3.7860e-02,  4.6699e-03],\n",
      "        [ 9.6753e-05,  3.8221e-02,  1.9658e-02,  ..., -6.3200e-03,\n",
      "          2.2407e-02, -1.6425e-02],\n",
      "        [ 5.9448e-02,  4.3217e-03,  1.6101e-02,  ..., -7.5925e-03,\n",
      "          7.5968e-03,  2.9488e-02],\n",
      "        ...,\n",
      "        [-1.2917e-02,  1.4802e-02,  6.9440e-03,  ...,  3.6022e-04,\n",
      "         -9.9758e-03,  9.7989e-03],\n",
      "        [-3.5000e-03,  4.5107e-02,  1.5952e-02,  ...,  3.1508e-02,\n",
      "          2.7726e-02,  3.5913e-02],\n",
      "        [-3.3904e-02,  1.7777e-02, -3.4840e-03,  ...,  2.9134e-03,\n",
      "         -1.7864e-03,  1.2128e-02]], requires_grad=True)\n",
      "\n",
      "Dequantized weights: \n",
      "tensor([[ 0.0245,  0.0245,  0.0000,  ...,  0.0061,  0.0368,  0.0061],\n",
      "        [ 0.0000,  0.0368,  0.0184,  ..., -0.0061,  0.0245, -0.0184],\n",
      "        [ 0.0613,  0.0061,  0.0184,  ..., -0.0061,  0.0061,  0.0306],\n",
      "        ...,\n",
      "        [-0.0123,  0.0123,  0.0061,  ...,  0.0000, -0.0123,  0.0123],\n",
      "        [-0.0061,  0.0429,  0.0184,  ...,  0.0306,  0.0306,  0.0368],\n",
      "        [-0.0368,  0.0184, -0.0061,  ...,  0.0000,  0.0000,  0.0123]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Original weights: ')\n",
    "print(model.linear1.weight)\n",
    "print('')\n",
    "print(f'Dequantized weights: ')\n",
    "print(torch.dequantize(quant_model.linear1.weight()))\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108df3be-822a-4bb2-b85c-5f9e1647f196",
   "metadata": {},
   "source": [
    "#### Lets compare Unquantized and Quantized models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9409872c-ae25-4c98-8975-d0cb8c6b9148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the model after quantization\n",
      "Size (KB): 52.77\n",
      "Testing the model after quantization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|████████████████████████████████████████████████████████████████████| 1000/1000 [00:02<00:00, 403.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print('Size of the model after quantization')\n",
    "print_size_of_model(quant_model)\n",
    "print('Testing the model after quantization')\n",
    "test(quant_model,None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e91029-539d-4927-85dd-7a79e8a42a59",
   "metadata": {},
   "source": [
    "The size has gone down from Size (KB): 187.364 to Size (KB): 52.77 and accuracy has gone from 0.9646 to 0.9626. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786007a4-3536-408b-897d-9cb17bcd7543",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0902dc-cf32-4ffd-af52-09258c531c15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdb22ed-eced-46c3-a044-c6bc92ee6462",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
