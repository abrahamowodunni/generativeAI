{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4127520a-7e05-4477-928a-e3fe9e274c00",
   "metadata": {},
   "source": [
    "### Singular Value Decomposition (SVD)\r\n",
    "\r\n",
    "In this section, we will explore the **Singular Value Decomposition (SVD)**, a powerful matrix factorization technique used for reducing dimensionality, noise filtering, and understanding matrix structures. Specifically, we will:\r\n",
    "\r\n",
    "- **Perform SVD on a matrix `W`**: This will decompose the matrix into three components: `U`, `S`, and `V^T`.\r\n",
    "- **Rank-r Approximation**: We will approximate the matrix `W` using a lower rank `r`, which retains the most important features of `W` while reducing its complexity.\r\n",
    "- **Compare original matrix with the decomposed form**: By checking the outputs from the original matrix and its rank-2 approximation, we will evaluate how well the approximation preserves the structure and behavior of the original matrix.\r\n",
    "  \r\n",
    "#### Key steps include:\r\n",
    "1. Generating a random, **rank-deficient matrix** `W`.\r\n",
    "2. Decomposing `W` using **SVD** into its components (`U`, `S`, and `V`).\r\n",
    "3. Retaining only the top `r` singular values and corresponding singular vectors to create a **rank-r approximation**.\r\n",
    "4. Verifying the accuracy of the approximation by comparing results of matrix-vector multiplication using both the original and approximated matrices.\r\n",
    "\r\n",
    "This notebook serves as a foundation for understanding how SVD can be used for dimensionality reduction, while maintaining the essential structure of data.\r\n",
    "\r\n",
    "---\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "540c398e-1fb3-48ce-9771-84945b96967f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "_ = torch.manual_seed(433)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab2dc1e-6a08-4e3b-9ef9-4544c8631b5c",
   "metadata": {},
   "source": [
    "### Generating the rank-deficient matrix W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f81b022-0553-41f2-a25c-988281959670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-6.3953e-02,  1.1302e-01, -3.7142e-01,  2.3373e-02, -7.8053e-01,\n",
       "          3.5072e-01, -8.2774e-01,  4.2444e-01, -6.8827e-01, -1.3864e+00],\n",
       "        [-2.7917e-02, -1.5275e-01, -1.7158e-02, -3.6261e-02,  2.8900e-01,\n",
       "          2.2474e-01,  2.0163e-02, -3.5775e-01,  1.8413e-01,  2.9737e-01],\n",
       "        [-4.1951e-02,  2.0541e-01, -3.3781e-01,  4.5515e-02, -9.2106e-01,\n",
       "          1.8352e-01, -7.9077e-01,  6.3117e-01, -7.6625e-01, -1.4957e+00],\n",
       "        [-1.4536e-01,  1.7327e-01, -7.8424e-01,  3.3899e-02, -1.5136e+00,\n",
       "          8.2684e-01, -1.7236e+00,  7.4004e-01, -1.3639e+00, -2.7777e+00],\n",
       "        [ 4.2426e-02,  2.5583e-01,  9.0820e-03,  6.0554e-02, -5.1303e-01,\n",
       "         -3.4996e-01, -7.5362e-02,  6.0735e-01, -3.3663e-01, -5.5774e-01],\n",
       "        [ 1.0137e-01,  5.7403e-02,  4.1904e-01,  1.7340e-02,  5.0010e-01,\n",
       "         -6.3980e-01,  8.6550e-01, -3.7138e-02,  5.2375e-01,  1.1411e+00],\n",
       "        [-2.1517e-01, -2.1269e-01, -8.2427e-01, -5.7694e-02, -7.7841e-01,\n",
       "          1.3902e+00, -1.6656e+00, -1.6529e-01, -8.9387e-01, -2.0162e+00],\n",
       "        [ 3.4170e-02, -2.7506e-01,  3.5245e-01, -6.1845e-02,  1.0860e+00,\n",
       "         -1.1128e-01,  8.4750e-01, -8.0362e-01,  8.8249e-01,  1.6995e+00],\n",
       "        [-1.7880e-01,  5.1648e-01, -1.1822e+00,  1.1144e-01, -2.8069e+00,\n",
       "          9.0946e-01, -2.6926e+00,  1.7254e+00, -2.4050e+00, -4.7714e+00],\n",
       "        [ 1.5422e-01, -2.7869e-03,  7.0214e-01,  5.6609e-03,  1.0416e+00,\n",
       "         -9.4139e-01,  1.4868e+00, -2.9865e-01,  1.0129e+00,  2.1384e+00]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d,k = 10,10\n",
    "w_rank = 2\n",
    "W = torch.randn(d,w_rank) @ torch.randn(w_rank,k)\n",
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc33673b-72d6-41f4-aafe-09db9ffa9795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The ranks of W is: 2'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluating the rank of W\n",
    "rank = torch.linalg.matrix_rank(W)\n",
    "f'The ranks of W is: {rank}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6373af-5d55-4207-bac3-0957d8917e3b",
   "metadata": {},
   "source": [
    "### üßÆ Generating the Rank-Deficient Matrix `W`\r\n",
    "\r\n",
    "In this step, we generate a **rank-deficient matrix** `W` by multiplying two random matrices. The result is a matrix with a rank lower than its full dimensions. This is essential for demonstrating **matrix factorization** techniques like SVD, as it gives us a concrete example to work with.\r\n",
    "\r\n",
    "- We set `W_rank = 2`, ensuring the matrix `W` has a rank of 2, despite its dimensions being `10x10`.\r\n",
    "- After constructing `W`, we calculate and display its rank to confirm that it is indeed **rank-deficient**.\r\n",
    "  \r\n",
    "This prepares us to apply **Singular Value Decomposition (SVD)** and later compare the results of matrix approximations. By using a lower-rank matrix, we create a practical scenario for exploring how well lower-rank factorizations capture the essence of the data.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ece39996-a665-450e-92e2-f9539f1bae71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of B: torch.Size([10, 2])\n",
      "Shape of A: torch.Size([2, 10])\n"
     ]
    }
   ],
   "source": [
    "# Performing SVD on W\n",
    "U,S,V = torch.svd(W)\n",
    "\n",
    "# For rank-r factorization, keep only the first r singular values (and corresponding columns of U and V)\n",
    "U_r = U[:, :w_rank]\n",
    "S_r = torch.diag(S[:w_rank])\n",
    "V_r = V[:, :w_rank].t()  # Transpose V_r to get the right dimensions\n",
    "\n",
    "# Compute B = U_r * S_r and A = V_r\n",
    "B = U_r @ S_r\n",
    "A = V_r\n",
    "print(f'Shape of B: {B.shape}')\n",
    "print(f'Shape of A: {A.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7136e4-dd51-425d-a16e-6551a4dcfea1",
   "metadata": {},
   "source": [
    "### üîç Comparing the Original Matrix `W` with its Decomposed Form\n",
    "\n",
    "In this part, we explore how well the **rank-reduced approximation** of the matrix `W` performs when applied to a linear transformation. This is done by comparing the results of the matrix-vector multiplication using both:\n",
    "\n",
    "- The **original matrix** `W`, and\n",
    "- The **decomposed matrices** `B @ A` (our rank-2 approximation).\n",
    "\n",
    "üí° **Key concepts**:\n",
    "- We simulate a basic **linear regression** scenario, where \\( y = W \\cdot x + \\text{bias} \\) represents the output of a neural network's layer or a linear model.\n",
    "- We generate a random **input vector** and a **bias** to simulate the input to the matrix `W` and its decomposed form.\n",
    "- We then compute the output using both the **full matrix** `W` and its **rank-2 approximation** (`B @ A`).\n",
    "\n",
    "After comparing the outputs:\n",
    "- The results from the original matrix `W` and the rank-2 approximation are nearly identical. This shows that the **low-rank approximation** preserves the key information.\n",
    "  \n",
    "Lastly, we compare the **number of parameters**:\n",
    "- The original matrix `W` has more parameters compared to the **decomposed form**, which uses fewer parameters while still producing comparable results. This highlights the benefits of using **SVD for dimensionality reduction**‚Äîfewer parameters, lower complexity, but similar performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fd670f4-99be-4dfc-a953-43d15051f2aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original y using W:\n",
      " tensor([-2.1266,  0.9178, -1.0260, -5.2443, -0.2655,  0.5081, -3.4994,  2.7782,\n",
      "        -5.6096,  2.2747])\n",
      "\n",
      "y' computed using BA:\n",
      " tensor([-2.1266,  0.9178, -1.0260, -5.2443, -0.2655,  0.5081, -3.4994,  2.7782,\n",
      "        -5.6096,  2.2747])\n"
     ]
    }
   ],
   "source": [
    "# Generate random bias and input (imagine we are working with a Neural Network)\n",
    "bias = torch.randn(d)\n",
    "x = torch.randn(d)\n",
    "\n",
    "#our linear regression y = mx + b\n",
    "y = W @ x + bias\n",
    "\n",
    "# Same thing but for our decomposed, y' = (a*b)x + b\n",
    "y_prime = (B @ A) @ x + bias\n",
    "\n",
    "# comparison\n",
    "print(\"Original y using W:\\n\", y)\n",
    "print(\"\")\n",
    "print(\"y' computed using BA:\\n\", y_prime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71ff877c-ec9a-4ec9-a7ba-644924be09a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters of W:  100\n",
      "Total parameters of B and A:  40\n"
     ]
    }
   ],
   "source": [
    "print(\"Total parameters of W: \", W.nelement())\n",
    "print(\"Total parameters of B and A: \", B.nelement() + A.nelement())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb6adac-f9ac-49ab-a495-10b4d7ed0a01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9786ed58-b0a5-4131-b0d9-41498cc38e95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74079d6-5453-432c-8f79-d061d2ddac9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a259da-82f7-4e3f-94d8-68b9b5912652",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7235af65-6e26-47fc-b9e0-4c3298d54135",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfd8fbd-fe19-423b-9c76-becbf589c334",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2bd6b5-536c-40fb-a6e6-c1ad690d5999",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30669941-9fbf-4538-bdb1-c2edeacef1bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c5e1b2-4a64-4bdb-b780-c025396d37d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348251e1-cd5c-4f39-82d0-039666974130",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf95ca3-d197-426b-ad4b-06a28c226b3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17171d9a-c579-4836-906c-f39c40048171",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2189f4b3-18f2-4b56-8408-b57b50b813ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1b0f21-8634-4119-9fe8-6cb5dc3a0ffd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cb5e75-0b12-4faf-961a-72e560c2ae0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4dfa6b-242f-4475-8a7f-a053a21639f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410b08fe-bae3-4449-a06a-8f1030319d1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4dbdb8-97d0-47a5-87b7-1e47af8bcf83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e25d50-0f36-4bcb-8fc9-dfcc48a4d160",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d815db0-a014-4773-8d24-e243f7b42b61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21cca650-7cd5-4f59-95f1-77b10dac8af3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c386324c-08fc-4d2c-8e55-73d9f0f7f52b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b806d708-df5d-44ea-86c1-297beee35d97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d38900b-9921-42f1-a54e-71411532e4c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f81ab48-c028-4249-a7ae-e656c54aa5bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493f7236-ee78-406d-9122-026779ce6f64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574bed21-3c5e-4674-b02e-8151905bc32d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
